{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "22572ec5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_openml\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, roc_auc_score\n",
    "import numpy as np\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "2ac8ebab",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = fetch_openml('compas-two-years')\n",
    "X, y = dataset.data, dataset.target\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "826f338f",
   "metadata": {},
   "source": [
    "# Let's train a simple predictor on that"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5d2652a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = GradientBoostingClassifier()\n",
    "clf.fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "clf.score(X_test, y_test)  # note: I think here >65 % accuracy is quite OK because it is a very hard task, checking: \"compas dataset accuracy\" on google it seems often around 65 %"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d58fbfe0",
   "metadata": {},
   "source": [
    "# We try to detect if the classifier has a bad equality of \"opportunity\" bias\n",
    "\n",
    "That is, if it will predict more false positive on African Americans than others: that is, if even if you're innocent, being African American is more risky for you if you go through the algorithm..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "b427129f",
   "metadata": {},
   "outputs": [],
   "source": [
    "tn_aa, fp_aa, fn_aa, tp_aa = confusion_matrix(y_pred[X_test['race_African-American'] == '1'], y_test[X_test['race_African-American'] == '1']).ravel()\n",
    "tn_w, fp_w, fn_w, tp_w = confusion_matrix(y_pred[X_test['race_Caucasian'] == '1'], y_test[X_test['race_Caucasian'] == '1']).ravel()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f403dee9",
   "metadata": {},
   "source": [
    "We compute the false positive rate on each category: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "15d0fc66",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3542713567839196"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fp_aa/(fp_aa+tn_aa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "ed62f493",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3194805194805195"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fp_w/(fp_w+tn_w)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1083955",
   "metadata": {},
   "source": [
    "Therefore, we see that indeed, our classifier has a higher false positive rate for African Americans, meaning given a person is **not a recidivist**, the algorithm is more likely to (wrongly) classify it as a recidivist if they are African American than if they are White Caucasian.\n",
    "\n",
    "Let's look at the difference of AUC too:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "f39d8a8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = clf.decision_function(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "0b16e006",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "auc aa: 0.7277288823407775\n",
      "auc w: 0.6853405070754717\n"
     ]
    }
   ],
   "source": [
    "auc_1 = roc_auc_score(y_test[X_test['race_African-American'] == '1'], scores[np.array(X_test['race_African-American'] == '1')])\n",
    "auc_2 = roc_auc_score(y_test[X_test['race_African-American'] == '0'], scores[np.array(X_test['race_African-American'] == '0')])\n",
    "print('auc aa: {}'.format(auc_1))\n",
    "print('auc w: {}'.format(auc_2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "250768fc",
   "metadata": {},
   "source": [
    "Interesting, I would've thought the AUC would be higher on w, since there are more false positives on aa... Anyways let's see if trying to put the same AUC for both would help improve fairness"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10635bc8",
   "metadata": {},
   "source": [
    "# Now let's try to code a differentiable cost function that, if optimized for, can reduce this gap\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e17140c0",
   "metadata": {},
   "source": [
    "We try to implement a differentiable, AUC based, metric for fairness, using for now section E.1 from https://arxiv.org/pdf/2002.08159.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "542337a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid_torch(x):\n",
    "    return 1/(1+torch.exp(-x))\n",
    "\n",
    "def auc_approx_torch(scores, y_true):\n",
    "    # y_true must be 0 or 1, scores must be from minus inf to plus inf (some decision function)\n",
    "    # an approximated (differentiable) version of auc\n",
    "    N_neg = (y_true == 1).sum()\n",
    "    N_pos = (y_true == 0).sum()\n",
    "    return 0.5 * 1/(N_neg + N_pos) * (sigmoid((scores[:, None] - score[None]) * (y_true[:, None] - y_true[None]))).sum()\n",
    "\n",
    "# we also define the batch-wise version, for B pairs randomly sampled:\n",
    "def auc_approx_batch_torch(scores_i, scores_j, y_true_i, y_true_j):\n",
    "    # scores_i is the set of first scores of the first elements sampled, same for y_true_i\n",
    "    B = scores_i.shape[0]\n",
    "    if B != 0:\n",
    "        return 1/B * (sigmoid_torch((scores_i - scores_j) * (y_true_i - y_true_j))).sum()\n",
    "    else: \n",
    "        return 0\n",
    "\n",
    "\n",
    "def diff_fairness_torch(sensitive_attr, scores_i, scores_j, y_true_i, y_true_j):\n",
    "    auc_sensitive_1 = auc_approx_batch_torch(scores_i[sensitive_attr==0], \n",
    "                                       scores_j[sensitive_attr==0],\n",
    "                                       y_true_i[sensitive_attr==0],\n",
    "                                       y_true_j[sensitive_attr==0])\n",
    "    auc_sensitive_2 = auc_approx_batch_torch(scores_i[sensitive_attr==1], \n",
    "                                       scores_j[sensitive_attr==1],\n",
    "                                       y_true_i[sensitive_attr==1],\n",
    "                                       y_true_j[sensitive_attr==1])\n",
    "    # I add squared here so that minimizing it will try to put this term to zero\n",
    "    return (auc_sensitive_1 - auc_sensitive_2)**2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3630b547",
   "metadata": {},
   "source": [
    "Let us run a simple neural network, with the above penalty for fairness, see if it improves fairness or not"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "e74c4e68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we forget about the test set for now: we take the whole dataset\n",
    "X_train = np.array(X, dtype=np.float32)\n",
    "y_train = np.array(y, dtype=np.float32)[:, None]  # this shape is necessary for pytorch\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X_train, y_train, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "c36a2f38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# warning: the sampling for the computation of that metric should be some *pairs* from the validation set \n",
    "ce = torch.nn.BCELoss()\n",
    "    \n",
    "def total_loss(y_pred, y, sensitive_attr, scores_i, scores_j, y_true_i, y_true_j):\n",
    "    return ce(y_pred, y) + 0.2 * diff_fairness_torch(sensitive_attr, scores_i, scores_j, y_true_i, y_true_j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "82e2f5ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99 0.7628890872001648\n",
      "199 0.757701575756073\n",
      "299 0.5764566659927368\n",
      "399 0.6320579648017883\n",
      "499 0.6995129585266113\n",
      "599 0.8715802431106567\n",
      "699 0.5928434133529663\n",
      "799 0.806164026260376\n",
      "899 0.44155460596084595\n",
      "999 0.8556731939315796\n",
      "1099 0.6114168763160706\n",
      "1199 0.837361752986908\n",
      "1299 0.8014306426048279\n",
      "1399 0.49813297390937805\n",
      "1499 0.48914673924446106\n",
      "1599 0.7856320738792419\n",
      "1699 0.8316701650619507\n",
      "1799 0.6041955947875977\n",
      "1899 0.5523978471755981\n",
      "1999 0.6871882677078247\n"
     ]
    }
   ],
   "source": [
    "# took code from https://pytorch.org/tutorials/beginner/pytorch_with_examples.html\n",
    "\n",
    "import torch\n",
    "import math\n",
    "\n",
    "# Use the nn package to define our model and loss function.\n",
    "model = torch.nn.Sequential(\n",
    "    torch.nn.Linear(13, 1),\n",
    "    torch.nn.Sigmoid())\n",
    "\n",
    "learning_rate = 1e-3\n",
    "optimizer = torch.optim.RMSprop(model.parameters(), lr=learning_rate)\n",
    "\n",
    "\n",
    "len_train_data = X_train.shape[0]\n",
    "batch_size = 10\n",
    "pairs_batch_size = 10\n",
    "val_cat = {0: None, 1:None}\n",
    "val_cat[0] = X_valid[X_valid[:, 10] == 0]  # The tenth column corresponds to AfricanAmerican categorial variable\n",
    "val_cat[1] = X_valid[X_valid[:, 10] == 1]\n",
    "for t in range(2000):\n",
    "    \n",
    "    # we sample a batch of training samples and a batch of validation pairs\n",
    "    BT = np.random.randint(len_train_data, size=batch_size)  # not efficient at all but we don t care\n",
    "    xx = torch.tensor(X_train[BT])\n",
    "    yy = torch.tensor(y_train[BT])\n",
    "    pairs_x_i = []\n",
    "    pairs_x_j = []\n",
    "    y_i = []\n",
    "    y_j = []\n",
    "    sensitive_attr = []\n",
    "    for _ in range(pairs_batch_size):  # super slow but we don't care\n",
    "        sens_attr_chosen = np.random.randint(2) # we first sample a sensitive attribute (AA/W, here 0/1)\n",
    "        # then we sample a pair of validation samples for this sensitive attribute\n",
    "        val_slice_chosen = val_cat[np.random.randint(2)]\n",
    "        pairs_idx = np.random.randint(val_slice_chosen.shape[0], size=2)\n",
    "        pairs_x_i.append(val_slice_chosen[pairs_idx[0]])\n",
    "        pairs_x_j.append(val_slice_chosen[pairs_idx[1]])\n",
    "        y_i.append(y_valid[pairs_idx[0]])\n",
    "        y_j.append(y_valid[pairs_idx[1]])\n",
    "        sensitive_attr.append(sens_attr_chosen)\n",
    "    pairs_x_i = torch.tensor(pairs_x_i)\n",
    "    pairs_x_j = torch.tensor(pairs_x_j)\n",
    "    y_i = torch.tensor(y_i)\n",
    "    y_j = torch.tensor(y_j)\n",
    "    sensitive_attr = torch.tensor(sensitive_attr)\n",
    "    \n",
    "    y_pred = model(xx)\n",
    "    scores_i = model(pairs_x_i)\n",
    "    scores_j = model(pairs_x_j)\n",
    "    \n",
    "    # Compute and print loss.\n",
    "    loss = total_loss(y_pred, yy, sensitive_attr, scores_i, scores_j, y_i, y_j)\n",
    "    if t % 100 == 99:\n",
    "        print(t, loss.item())\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5583785a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
