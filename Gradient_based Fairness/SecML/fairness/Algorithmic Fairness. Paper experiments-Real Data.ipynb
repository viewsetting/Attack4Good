{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from IPython.display import Markdown, display\n",
    "from matplotlib.lines import Line2D\n",
    "\n",
    "import time\n",
    "import tqdm\n",
    "import warnings\n",
    "from scipy import integrate\n",
    "\n",
    "from scipy import stats\n",
    "random_state = 999\n",
    "from copy import deepcopy\n",
    "\n",
    "\n",
    "\n",
    "## General importsÇ\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set()\n",
    "\n",
    "from matplotlib.colors import ListedColormap\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "## SKLearn imports\n",
    "from sklearn import linear_model, svm\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn import svm\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "\n",
    "## AIF360 imports\n",
    "from aif360.datasets import BinaryLabelDataset, StandardDataset\n",
    "from aif360.metrics import BinaryLabelDatasetMetric, ClassificationMetric\n",
    "\n",
    "from aif360.datasets import AdultDataset, GermanDataset, CompasDataset\n",
    "from aif360.metrics.utils import compute_boolean_conditioning_vector\n",
    "\n",
    "from aif360.algorithms.preprocessing.optim_preproc import OptimPreproc\n",
    "from aif360.algorithms.preprocessing import Reweighing\n",
    "from aif360.algorithms.preprocessing.optim_preproc_helpers.data_preproc_functions\\\n",
    "            import load_preproc_data_adult, load_preproc_data_german, load_preproc_data_compas\n",
    "from aif360.algorithms.preprocessing.optim_preproc_helpers.distortion_functions\\\n",
    "            import get_distortion_adult, get_distortion_german, get_distortion_compas\n",
    "\n",
    "from aif360.algorithms.preprocessing.optim_preproc_helpers.opt_tools import OptTools\n",
    "\n",
    "\n",
    "#SEC_ML imports\n",
    "from secml.data.c_dataset import CDataset\n",
    "from secml.ml.classifiers import CClassifierSVM, CClassifierLogistic\n",
    "from secml.ml.kernels import CKernelRBF, CKernelLinear\n",
    "from secml.ml.peval.metrics import CMetricAccuracy\n",
    "from secml.data.splitter import CDataSplitterKFold\n",
    "\n",
    "# Poisoning attacks\n",
    "from secml.adv.attacks import CAttackPoisoningSVM\n",
    "from secml.adv.attacks.poisoning.c_attack_poisoning_logistic_regression import CAttackPoisoningLogisticRegression"
   ],
   "outputs": [
    {
     "output_type": "error",
     "ename": "RuntimeError",
     "evalue": "module compiled against API version 0xe but this version of numpy is 0xd",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;31mRuntimeError\u001b[0m: module compiled against API version 0xe but this version of numpy is 0xd"
     ]
    },
    {
     "output_type": "error",
     "ename": "RuntimeError",
     "evalue": "module compiled against API version 0xe but this version of numpy is 0xd",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;31mRuntimeError\u001b[0m: module compiled against API version 0xe but this version of numpy is 0xd"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "custom_palette=sns.diverging_palette(255, 133, l=60, n=12, center=\"dark\")\n",
    "sns.palplot(sns.color_palette(\"Paired\", 12))\n",
    "sns.set_palette(sns.color_palette(\"Paired\"))\n",
    "sns.set_style(\"white\")\n",
    "sns.set_context(\"paper\", rc={\"font.size\":16,\"axes.titlesize\":20,\"axes.labelsize\":16})"
   ],
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAArgAAABQCAYAAADySAbpAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4zLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvnQurowAAA3FJREFUeJzt2z+LXGUAxeGT7MbsYpCwCHFlQQs7C6ugQrZRwUqrICQfQuysFNHKTku/QAIiNqlCgk0WjKSyFQuFxRWRECRhTDbrWPgH0s0Oe3nD4XmaO8W8zJnm3h8Dc2w+nwcAAFocHz0AAACOksAFAKCKwAUAoIrABQCgisAFAKCKwAUAoIrABQCgisAFAKCKwAUAoIrABQCgyuoSZ04mOZtkL8nB0c4BAID/rSTZTHIryf1FDy0TuGeT3FjiHAAALGM7yc6ib14mcPeS5NoPv2W23/kD7tsvbubcp9+MnjGZnfdfy/XdL0bPmMTnN7/OlfNX89ZXb46eMokr56/m4eVLo2dMZvXCxey9/OroGZPZ/O7b/HXz49EzJnP8lQ+Tz54fPWM67/2U76//OHrFJF5644V88M7l0TMm88mXF5L03juTi7n27uujR0xibeNMtj+6lPzbn4taJnAPkmS2f5B7DzoDN0l278xGT5jU7OEfoydMYu/eL49cK929O3rBpA52d0dPmNaft0cvmNadn0cvmNSD2f7oCZO5/Wv3vSXp/n6z34ufe/84VHT6kxkAAFUELgAAVQQuAABVBC4AAFUELgAAVQQuAABVBC4AAFUELgAAVQQuAABVBC4AAFUELgAAVQQuAABVBC4AAFUELgAAVQQuAABVBC4AAFUELgAAVQQuAABVBC4AAFUELgAAVQQuAABVBC4AAFUELgAAVQQuAABVBC4AAFUELgAAVQQuAABVBC4AAFUELgAAVQQuAABVBC4AAFUELgAAVQQuAABVBC4AAFUELgAAVQQuAABVBC4AAFUELgAAVQQuAABVBC4AAFUELgAAVQQuAABVBC4AAFUELgAAVQQuAABVBC4AAFUELgAAVQQuAABVBC4AAFUELgAAVQQuAABVVpc4s5Ik6ydWjnjK42Xr9ProCZNaX31q9IRJbD757CPXSqdOjV4wqZWtrdETprW2MXrBtE4/N3rBpJ5YPzF6wmQ2num+tyTd32/96c7n3trGmf9eHio8j83n88N+1rkkNw57CAAAlrSdZGfRNy8TuCeTnE2yl+TgsIcBAGBBK0k2k9xKcn/RQ8sELgAAPLb8yQwAgCoCFwCAKgIXAIAqAhcAgCoCFwCAKgIXAIAqAhcAgCoCFwCAKgIXAIAqAhcAgCp/A65JaH/JHWjgAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 864x72 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     }
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 1. Data Generator"
   ],
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt # for plotting stuff\n",
    "from random import seed, shuffle\n",
    "from scipy.stats import multivariate_normal # generating synthetic data\n",
    "SEED = 999\n",
    "seed(SEED) # set the random seed so that the random permutations can be reproduced again\n",
    "np.random.seed(SEED)\n",
    "\n",
    "def get_data(dataset_used = \"compas\"):\n",
    "    # import dataset\n",
    "    #sdataset_used = \"compas\" # \"adult\", \"german\", \"compas\"\n",
    "    protected_attribute_used = 1 # 1, 2\n",
    "\n",
    "    if dataset_used == \"adult\":\n",
    "        if protected_attribute_used == 1:\n",
    "            privileged_groups = [{'sex': 1}]\n",
    "            unprivileged_groups = [{'sex': 0}]\n",
    "            dataset_orig = load_preproc_data_adult(['sex'])\n",
    "        else:\n",
    "            privileged_groups = [{'race': 1}]\n",
    "            unprivileged_groups = [{'race': 0}]\n",
    "            dataset_orig = load_preproc_data_adult(['race'])\n",
    "\n",
    "        optim_options = {\n",
    "            \"distortion_fun\": get_distortion_adult,\n",
    "            \"epsilon\": 0.05,\n",
    "            \"clist\": [0.99, 1.99, 2.99],\n",
    "            \"dlist\": [.1, 0.05, 0]\n",
    "        }\n",
    "\n",
    "    elif dataset_used == \"german\":\n",
    "        if protected_attribute_used == 1:\n",
    "            privileged_groups = [{'sex': 1}]\n",
    "            unprivileged_groups = [{'sex': 0}]\n",
    "            dataset_orig = load_preproc_data_german(['sex'])\n",
    "            optim_options = {\n",
    "                \"distortion_fun\": get_distortion_german,\n",
    "                \"epsilon\": 0.05,\n",
    "                \"clist\": [0.99, 1.99, 2.99],\n",
    "                \"dlist\": [.1, 0.05, 0]\n",
    "            }\n",
    "            ## Changing labels to 0-1\n",
    "            dataset_orig.labels[dataset_orig.labels==2]=0\n",
    "            dataset_orig.unfavorable_label=0.0\n",
    "\n",
    "        else:\n",
    "            privileged_groups = [{'age': 1}]\n",
    "            unprivileged_groups = [{'age': 0}]\n",
    "            dataset_orig = load_preproc_data_german(['age'])\n",
    "            optim_options = {\n",
    "                \"distortion_fun\": get_distortion_german,\n",
    "                \"epsilon\": 0.1,\n",
    "                \"clist\": [0.99, 1.99, 2.99],\n",
    "                \"dlist\": [.1, 0.05, 0]\n",
    "            }    \n",
    "\n",
    "    elif dataset_used == \"compas\":\n",
    "        if protected_attribute_used == 1:     \n",
    "            privileged_groups = [{'sex': 1}]\n",
    "            unprivileged_groups = [{'sex': 0}]\n",
    "            dataset_orig = load_preproc_data_compas(['sex'])\n",
    "        else:\n",
    "            privileged_groups = [{'race': 1}]\n",
    "            unprivileged_groups = [{'race': 0}]\n",
    "            dataset_orig = load_preproc_data_compas(['race'])\n",
    "\n",
    "        optim_options = {\n",
    "            \"distortion_fun\": get_distortion_compas,\n",
    "            \"epsilon\": 0.05,\n",
    "            \"clist\": [0.99, 1.99, 2.99],\n",
    "            \"dlist\": [.1, 0.05, 0]\n",
    "        }\n",
    "\n",
    "\n",
    "    #random seed\n",
    "    np.random.seed(1)\n",
    "\n",
    "    dataset_aif360 = dataset_orig\n",
    "    \n",
    "    # Split into train, validation, and test\n",
    "    dataset_orig_train, dataset_orig_vt = dataset_aif360.split([0.2], shuffle=True)\n",
    "    dataset_orig_valid, dataset_orig_test = dataset_orig_vt.split([0.5], shuffle=True)\n",
    "    \n",
    "    dataset_aif360 = dataset_orig_train.copy()\n",
    "    \n",
    "    SENSIBLE_ATT_INDEX = dataset_orig.feature_names.index(dataset_orig.protected_attribute_names[0])\n",
    "\n",
    "    ## Correcting labels assignation\n",
    "    if dataset_aif360.unfavorable_label != 0:\n",
    "        Y = dataset_aif360.labels\n",
    "        Y[Y == dataset_aif360.unfavorable_label] = -1\n",
    "        Y[Y == dataset_aif360.favorable_label] = 1\n",
    "        Y[Y == -1] = 0\n",
    "\n",
    "        dataset_aif360.unfavorable_label = 0\n",
    "        dataset_aif360.favorable_label = 1\n",
    "    #np.delete(dataset_aif360.features, SENSIBLE_ATT_INDEX, axis=1)    \n",
    "    sec_ml_dataset = CDataset(dataset_aif360.features , dataset_aif360.labels)\n",
    "    \n",
    "    return sec_ml_dataset.X.get_data(), sec_ml_dataset.Y.get_data(), SENSIBLE_ATT_INDEX\n",
    "    \n",
    "import math\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt # for plotting stuff\n",
    "from random import seed, shuffle\n",
    "from scipy.stats import multivariate_normal # generating synthetic data\n",
    "SEED = 1122334455\n",
    "seed(SEED) # set the random seed so that the random permutations can be reproduced again\n",
    "np.random.seed(SEED)\n",
    "\n",
    "def get_data2(dataset_used = \"compas\"):\n",
    "    # import dataset\n",
    "    #sdataset_used = \"compas\" # \"adult\", \"german\", \"compas\"\n",
    "    protected_attribute_used = 1 # 1, 2\n",
    "\n",
    "    if dataset_used == dataset_used:\n",
    "        if protected_attribute_used == 1:\n",
    "            privileged_groups = [{'sex': 1}]\n",
    "            unprivileged_groups = [{'sex': 0}]\n",
    "            dataset_orig = load_preproc_data_adult(['sex'])\n",
    "        else:\n",
    "            privileged_groups = [{'race': 1}]\n",
    "            unprivileged_groups = [{'race': 0}]\n",
    "            dataset_orig = load_preproc_data_adult(['race'])\n",
    "\n",
    "        optim_options = {\n",
    "            \"distortion_fun\": get_distortion_adult,\n",
    "            \"epsilon\": 0.05,\n",
    "            \"clist\": [0.99, 1.99, 2.99],\n",
    "            \"dlist\": [.1, 0.05, 0]\n",
    "        }\n",
    "\n",
    "    elif dataset_used == \"german\":\n",
    "        if protected_attribute_used == 1:\n",
    "            privileged_groups = [{'sex': 1}]\n",
    "            unprivileged_groups = [{'sex': 0}]\n",
    "            dataset_orig = load_preproc_data_german(['sex'])\n",
    "            optim_options = {\n",
    "                \"distortion_fun\": get_distortion_german,\n",
    "                \"epsilon\": 0.05,\n",
    "                \"clist\": [0.99, 1.99, 2.99],\n",
    "                \"dlist\": [.1, 0.05, 0]\n",
    "            }\n",
    "            ## Changing labels to 0-1\n",
    "            dataset_orig.labels[dataset_orig.labels==2]=0\n",
    "            dataset_orig.unfavorable_label=0.0\n",
    "\n",
    "        else:\n",
    "            privileged_groups = [{'age': 1}]\n",
    "            unprivileged_groups = [{'age': 0}]\n",
    "            dataset_orig = load_preproc_data_german(['age'])\n",
    "            optim_options = {\n",
    "                \"distortion_fun\": get_distortion_german,\n",
    "                \"epsilon\": 0.1,\n",
    "                \"clist\": [0.99, 1.99, 2.99],\n",
    "                \"dlist\": [.1, 0.05, 0]\n",
    "            }    \n",
    "\n",
    "    elif dataset_used == \"compas\":\n",
    "        if protected_attribute_used == 1:     \n",
    "            privileged_groups = [{'sex': 1}]\n",
    "            unprivileged_groups = [{'sex': 0}]\n",
    "            dataset_orig = load_preproc_data_compas(['sex'])\n",
    "        else:\n",
    "            privileged_groups = [{'race': 1}]\n",
    "            unprivileged_groups = [{'race': 0}]\n",
    "            dataset_orig = load_preproc_data_compas(['race'])\n",
    "\n",
    "        optim_options = {\n",
    "            \"distortion_fun\": get_distortion_compas,\n",
    "            \"epsilon\": 0.05,\n",
    "            \"clist\": [0.99, 1.99, 2.99],\n",
    "            \"dlist\": [.1, 0.05, 0]\n",
    "        }\n",
    "\n",
    "\n",
    "    #random seed\n",
    "    np.random.seed(1)\n",
    "\n",
    "    dataset_aif360 = dataset_orig\n",
    "    \n",
    "    # Split into train, validation, and test\n",
    "    dataset_orig_train, dataset_orig_vt = dataset_aif360.split([0.8], shuffle=True)\n",
    "    dataset_orig_valid, dataset_orig_test = dataset_orig_vt.split([0.5], shuffle=True)\n",
    "    \n",
    "    dataset_aif360 = dataset_orig_vt.copy()\n",
    "    \n",
    "    SENSIBLE_ATT_INDEX = dataset_orig.feature_names.index(dataset_orig.protected_attribute_names[0])\n",
    "\n",
    "    ## Correcting labels assignation\n",
    "    if dataset_aif360.unfavorable_label != 0:\n",
    "        Y = dataset_aif360.labels\n",
    "        Y[Y == dataset_aif360.unfavorable_label] = 1\n",
    "        Y[Y == dataset_aif360.favorable_label] = -1\n",
    "       \n",
    "        # original \n",
    "        # Y[Y == dataset_aif360.unfavorable_label] = -1   \n",
    "        # Y[Y == dataset_aif360.favorable_label] = 1\n",
    "        Y[Y == -1] = 0\n",
    "\n",
    "        dataset_aif360.unfavorable_label = 0\n",
    "        dataset_aif360.favorable_label = 1\n",
    "    #np.delete(dataset_aif360.features, SENSIBLE_ATT_INDEX, axis=1)    \n",
    "    sec_ml_dataset = CDataset(dataset_aif360.features , dataset_aif360.labels)\n",
    "    \n",
    "    return sec_ml_dataset.X.get_data(), sec_ml_dataset.Y.get_data(), SENSIBLE_ATT_INDEX\n",
    "    "
   ],
   "outputs": [],
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 2. Creating custom Weighted CLoss to solve the optimization"
   ],
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "\n",
    "from secml.ml.classifiers.loss import CLossClassification, CLossLogistic\n",
    "from secml.array import CArray"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "class CLossDisparateImpact(CLossClassification):\n",
    "    \"\"\"Surrogate function of disparate impact.\n",
    "\n",
    "    Attributes\n",
    "    ----------\n",
    "    class_type : 'log'\n",
    "    suitable_for : 'classification'\n",
    "\n",
    "    \"\"\"\n",
    "    __class_type = 'dimp_log'\n",
    "\n",
    "    def __init__(self, _privileged_condition):\n",
    "        self._privileged_condition = CArray(_privileged_condition)\n",
    "\n",
    "    def unprivileged(self):\n",
    "        \"\"\"Give 1 to unprivileged, 0 to privileged\"\"\"\n",
    "        y = CArray.zeros(self._privileged_condition.size)\n",
    "        y[self._privileged_condition == 0] = 1\n",
    "        return y\n",
    "\n",
    "    def loss(self, y_true, score, pos_label=1):\n",
    "        \"\"\"Computes loss_priv-loss_unpriv, which is what we aim to max\"\"\"\n",
    "        # give 1 to unpriv, 0 to priv\n",
    "        y = self.unprivileged()\n",
    "        p_priv = (y == 0).sum() / y.size\n",
    "        p_unpriv = (y == 1).sum() / y.size\n",
    "        # loss = (score >= 0) != y  # zero-one loss\n",
    "        loss = CLossLogistic().loss(y_true=y, score=score)  # smoothed version\n",
    "        loss[y == 1] *= -p_priv / p_unpriv  # rebalance class weights\n",
    "        return -abs(loss)\n",
    "\n",
    "    def dloss(self, y_true, score, pos_label=1):\n",
    "        \"\"\"Computes the derivative of the loss vs score.\"\"\"\n",
    "        y = self.unprivileged()\n",
    "        p_priv = (y == 0).sum() / y.size\n",
    "        p_unpriv = (y == 1).sum() / y.size\n",
    "        grad = CLossLogistic().dloss(y, score, pos_label)\n",
    "        grad[y == 1] *= -p_priv / p_unpriv  # rebalance class weights\n",
    "        return grad"
   ],
   "outputs": [],
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 3. Helper functions"
   ],
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "def calculate_disparate_impact(y,sensible_att_vals, privileged_classes=1, favorable_output=1, verbose=False):\n",
    "    \n",
    "    privileged = y[sensible_att_vals == privileged_classes]\n",
    "    unprivileged = y[sensible_att_vals != privileged_classes]\n",
    "    \n",
    "    unprivileged_favorable = unprivileged[unprivileged==favorable_output]\n",
    "    privileged_favorable = privileged[privileged==favorable_output]\n",
    "    \n",
    "    n1 =  (len(unprivileged_favorable)/ len(unprivileged))\n",
    "    n2 = (len(privileged_favorable)/ len(privileged))\n",
    "    \n",
    "    if verbose:\n",
    "        print(\"\\tUnprivileged favorable1: \", n1)\n",
    "        print(\"\\tPrivileged favorable2: \", n2)\n",
    "     \n",
    "    disparate_impact = n1 - n2 #(max(n2,0.1)) \n",
    "    return disparate_impact\n",
    "\n",
    "def calculate_error_rate_ratio(y_true, y_pred,sensible_att_vals, privileged_classes=1, favorable_output=1, verbose=True):\n",
    "    privileged_y_true = y_true[sensible_att_vals == privileged_classes]\n",
    "    unprivileged_y_true = y_true[sensible_att_vals != privileged_classes]\n",
    "    \n",
    "    privileged_y_pred = y_pred[sensible_att_vals == privileged_classes]\n",
    "    unprivileged_y_pred = y_pred[sensible_att_vals != privileged_classes]\n",
    "    \n",
    "    privileged_num_errors = len(privileged_y_true) - (len(np.where(np.isclose(privileged_y_true, privileged_y_pred))[0]))\n",
    "    unprivileged_num_errors = len(unprivileged_y_true) - (len(np.where(np.isclose(unprivileged_y_true, unprivileged_y_pred))[0]))\n",
    "    \n",
    "    if verbose:\n",
    "        print(\"\\tN1: \", n1)\n",
    "        print(\"\\tN2: \", n2)\n",
    "        \n",
    "    \n",
    "        \n",
    "    error_rate = (unprivileged_num_errors / len(unprivileged_y_true)) / (privileged_num_errors / len(privileged_y_true))\n",
    "    return error_rate\n",
    "\n",
    "#12[(𝐹𝑃𝑅𝐷=unprivileged−𝐹𝑃𝑅𝐷=privileged)+(𝑇𝑃𝑅𝐷=unprivileged−𝑇𝑃𝑅𝐷=privileged))]\n",
    "def get_average_odds_difference(y_true, y_pred, sensible_att_vals, privileged_classes=1, favorable_output=1):\n",
    "    \n",
    "    y_true = np.array(y_true)\n",
    "    y_pred = np.array(y_pred)    \n",
    "\n",
    "    sensible_att_vals = np.array(sensible_att_vals)\n",
    "                                 \n",
    "    privileged_y_true = y_true[sensible_att_vals == privileged_classes]\n",
    "    unprivileged_y_true = y_true[sensible_att_vals != privileged_classes]\n",
    "    \n",
    "    privileged_y_pred = y_pred[sensible_att_vals == privileged_classes]\n",
    "    unprivileged_y_pred = y_pred[sensible_att_vals != privileged_classes]\n",
    "                                 \n",
    "                                 \n",
    "    FPR_unprivileged = get_false_positive_rate(unprivileged_y_true, unprivileged_y_pred, favorable_output)\n",
    "    FPR_privileged = get_false_positive_rate(privileged_y_true, privileged_y_pred, favorable_output)\n",
    "    TPR_unprivileged = get_true_positive_rate(unprivileged_y_true, unprivileged_y_pred, favorable_output)\n",
    "    TPR_privileged = get_true_positive_rate(privileged_y_true, privileged_y_pred, favorable_output)\n",
    "                              \n",
    "    return 0.5 * abs((FPR_unprivileged - FPR_privileged) + (TPR_unprivileged - TPR_privileged))\n",
    "    \n",
    "    \n",
    "\n",
    "def get_false_positive_rate(y_true, y_pred, favorable_output):\n",
    "    _tmp1 = y_pred[y_true!=favorable_output]\n",
    "    fp = _tmp1[_tmp1 == favorable_output]\n",
    "    \n",
    "    N = len(y_true[y_true != favorable_output])\n",
    "    \n",
    "    if N == 0:\n",
    "        return 0\n",
    "    \n",
    "    return len(fp) / N\n",
    "\n",
    "def get_true_positive_rate(y_true, y_pred, favorable_output):\n",
    "    _tmp1 = y_pred[y_true==favorable_output]\n",
    "    fp = _tmp1[_tmp1 == favorable_output]\n",
    "    \n",
    "    P = len(y_true[y_true == favorable_output])\n",
    "    \n",
    "    if N == 0:\n",
    "        return 0\n",
    "    \n",
    "    return len(fp) / P\n",
    "    \n",
    "    \n",
    "def get_false_negative_rate(y_true, y_pred, favorable_output):\n",
    "    _tmp = y_pred[y_true==favorable_output]\n",
    "    \n",
    "    fn = _tmp[_tmp != favorable_output]\n",
    "    \n",
    "    P = len(y_true[y_true != favorable_output])\n",
    "    \n",
    "    if P == 0:\n",
    "        return 0\n",
    "    \n",
    "    return len(fn) / P\n",
    "\n",
    "def get_error_rates(y_true, y_pred, sensible_att_vals, privileged_classes=1, favorable_output=1, verbose=False):\n",
    "    y_true = np.array(y_true)\n",
    "    y_pred = np.array(y_pred)    \n",
    "\n",
    "    sensible_att_vals = np.array(sensible_att_vals)\n",
    "    \n",
    "    \n",
    "    \n",
    "    privileged_y_true = y_true[sensible_att_vals == privileged_classes]\n",
    "    unprivileged_y_true = y_true[sensible_att_vals != privileged_classes]\n",
    "    \n",
    "    privileged_y_pred = y_pred[sensible_att_vals == privileged_classes]\n",
    "    unprivileged_y_pred = y_pred[sensible_att_vals != privileged_classes]\n",
    "    \"\"\"\n",
    "    privileged_num_errors = len(privileged_y_true) - (len(np.where(np.isclose(privileged_y_true, privileged_y_pred))[0]))\n",
    "    unprivileged_num_errors = len(unprivileged_y_true) - (len(np.where(np.isclose(unprivileged_y_true, unprivileged_y_pred))[0]))\n",
    "    \n",
    "    if verbose:\n",
    "        print(\"\\tN1: \", n1)\n",
    "        print(\"\\tN2: \", n2)\n",
    "\n",
    "        error_rate = (unprivileged_num_errors / len(unprivileged_y_true)) / (privileged_num_errors / len(privileged_y_true))\n",
    "    \"\"\"\n",
    "    \n",
    "    FNR_privileged = get_false_negative_rate(privileged_y_true, privileged_y_pred, favorable_output)\n",
    "    FNR_unprivileged = get_false_negative_rate(unprivileged_y_true, unprivileged_y_pred, favorable_output)\n",
    "    \n",
    "    FPR_privileged = get_false_positive_rate(privileged_y_true, privileged_y_pred, favorable_output)\n",
    "    FPR_unprivileged = get_false_positive_rate(unprivileged_y_true, unprivileged_y_pred, favorable_output)\n",
    "    \n",
    "    \n",
    "    if verbose:\n",
    "        print(\"\\tFNR_1: \", FNR_privileged)\n",
    "        print(\"\\tFNR_2: \", FNR_unprivileged)\n",
    "        print(\"\\tFPR_1: \", FPR_privileged)\n",
    "        print(\"\\tFPR_2: \", FPR_unprivileged)\n",
    "    \n",
    "    FNR = -1\n",
    "    FPR = -1\n",
    "    \n",
    "    try:\n",
    "        FNR = FNR_unprivileged / FNR_privileged\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    try:\n",
    "        FPR = FPR_unprivileged / FPR_privileged\n",
    "    except:\n",
    "        pass\n",
    "        \n",
    "\n",
    "    return ({\"FNR\": FNR, \"FNR_privileged\":FNR_privileged, \"FNR_unprivileged\":FNR_unprivileged, \"FNR\": 1}, {\"FPR\":FPR, \"FPR_privileged\":FPR_privileged, \"FPR_unprivileged\":FPR_unprivileged})\n",
    "\n",
    "\n",
    "\n",
    "def train_LogReg(training_set, test_set):\n",
    "\n",
    "    \n",
    "    # Metric to use for training and performance evaluation\n",
    "    # Creation of the multiclass classifier\n",
    "    metric = CMetricAccuracy()\n",
    "\n",
    "    #clf = CClassifierSVM(kernel=CKernelRBF()) # Radial Basis Function (RBF) kernel.\n",
    "    #clf = CClassifierSVM(kernel=CKernelLinear()) # Linear kernel.\n",
    "    clf = CClassifierLogistic()\n",
    "    # Parameters for the Cross-Validation procedure\n",
    "    xval_params = {'C': [1, 10]}#, 'kernel.gamma': [0.1]}#, 5, 10, 25, 50, 100]}\n",
    "\n",
    "    # Let's create a 3-Fold data splitter\n",
    "    \n",
    "    xval_splitter = CDataSplitterKFold(num_folds=3, random_state=random_state)\n",
    "\n",
    "    # Select and set the best training parameters for the classifier\n",
    "    print(\"Estimating the best training parameters...\")\n",
    "    best_params = clf.estimate_parameters(\n",
    "        dataset=training_set,\n",
    "        parameters=xval_params,\n",
    "        splitter=xval_splitter,\n",
    "        metric='accuracy',\n",
    "        perf_evaluator='xval'\n",
    "    )\n",
    "\n",
    "    print(\"The best training parameters are: \", best_params)\n",
    "\n",
    "    # We can now fit the classifier\n",
    "    clf.fit(training_set)\n",
    "    print(\"Training of classifier complete!\")\n",
    "\n",
    "    # Compute predictions on a test set\n",
    "    y_pred = clf.predict(test_set.X)\n",
    "\n",
    "    # Evaluate the accuracy of the classifier\n",
    "    acc = metric.performance_score(y_true=test_set.Y, y_pred=y_pred)\n",
    "\n",
    "    print(\"Accuracy on test set: {:.2%}\".format(acc))\n",
    "    \n",
    "    return clf, acc\n",
    "\n",
    "def train_SVM(training_set, test_set):\n",
    "\n",
    "    \n",
    "    # Metric to use for training and performance evaluation\n",
    "    # Creation of the multiclass classifier\n",
    "    metric = CMetricAccuracy()\n",
    "\n",
    "    #clf = CClassifierSVM(kernel=CKernelRBF()) # Radial Basis Function (RBF) kernel.\n",
    "    clf = CClassifierSVM(kernel=CKernelLinear()) # Linear kernel.\n",
    "    #clf = CClassifierLogistic()\n",
    "    # Parameters for the Cross-Validation procedure\n",
    "    xval_params = {'C': [1, 10]}#,'kernel.gamma': [0.1, 5, 10, 25, 50, 100]}\n",
    "\n",
    "    # Let's create a 3-Fold data splitter\n",
    "    \n",
    "    xval_splitter = CDataSplitterKFold(num_folds=3, random_state=random_state)\n",
    "\n",
    "    # Select and set the best training parameters for the classifier\n",
    "    print(\"Estimating the best training parameters...\")\n",
    "    best_params = clf.estimate_parameters(\n",
    "        dataset=training_set,\n",
    "        parameters=xval_params,\n",
    "        splitter=xval_splitter,\n",
    "        metric='accuracy',\n",
    "        perf_evaluator='xval'\n",
    "    )\n",
    "\n",
    "    print(\"The best training parameters are: \", best_params)\n",
    "\n",
    "    # We can now fit the classifier\n",
    "    clf.fit(training_set)\n",
    "    print(\"Training of classifier complete!\")\n",
    "\n",
    "    # Compute predictions on a test set\n",
    "    y_pred = clf.predict(test_set.X)\n",
    "\n",
    "    # Evaluate the accuracy of the classifier\n",
    "    acc = metric.performance_score(y_true=test_set.Y, y_pred=y_pred)\n",
    "\n",
    "    print(\"Accuracy on test set: {:.2%}\".format(acc))\n",
    "    \n",
    "    return clf, acc\n",
    "    "
   ],
   "outputs": [],
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "def execute_adversarial_attack(surrogate_clf, training_set, validation_set, test_set, sensible_att_in_test, privileged_condition_validation, percentage_pois=0.2):\n",
    "\n",
    "    print(\" ==> Adversarial attack. Percentage of samples: {} \".format(percentage_pois))\n",
    "    metric = CMetricAccuracy()\n",
    "    NUM_SAMPLES_TRAIN = training_set.num_samples\n",
    "    n_poisoning_points = int(NUM_SAMPLES_TRAIN * percentage_pois) # Number of poisoning points to generate\n",
    "    print(\"Creating {} poisoning samples \".format(n_poisoning_points))\n",
    "    # Should be chosen depending on the optimization problem\n",
    "    solver_params = {\n",
    "        'eta': 0.05,\n",
    "        'eta_min': 0.05,\n",
    "        'eta_max': None,\n",
    "        'max_iter': 1000,\n",
    "        'eps': 1e-6\n",
    "    }\n",
    "\n",
    "\n",
    "    pois_attack = CAttackPoisoningLogisticRegression(classifier=surrogate_clf,\n",
    "                                      training_data=training_set,\n",
    "                                      surrogate_classifier=surrogate_clf,\n",
    "                                      surrogate_data=validation_set,\n",
    "                                      val=validation_set,\n",
    "                                      distance='l2',\n",
    "                                      dmax=10,\n",
    "                                      lb=validation_set.X.min(), ub=validation_set.X.max(),\n",
    "                                      solver_params=solver_params,\n",
    "                                      random_seed=random_state,\n",
    "                                      init_type=\"random\")\n",
    "\n",
    "    pois_attack.n_points = n_poisoning_points\n",
    "    \n",
    "    dimp_loss = CLossDisparateImpact(privileged_condition_validation)\n",
    "    pois_attack._attacker_loss = dimp_loss\n",
    "\n",
    "    # Run the poisoning attack\n",
    "    print(\"Attack started...\")\n",
    "    pois_y_pred, pois_scores, pois_ds, f_opt = pois_attack.run(test_set.X, test_set.Y)\n",
    "    print(\"Attack complete!\")\n",
    "\n",
    "    \n",
    "    pois_tr = training_set.deepcopy().append(pois_ds)  # Join the training set with the poisoning points\n",
    "   \n",
    "    return pois_ds, pois_tr\n",
    "\n",
    "\n",
    "def execute_normal_poisoning_attack(surrogate_clf, training_set, validation_set, test_set, sensible_att_in_test, privileged_condition_validation, percentage_pois=0.2):\n",
    "\n",
    "    metric = CMetricAccuracy()\n",
    "    NUM_SAMPLES_TRAIN = training_set.num_samples\n",
    "    n_poisoning_points = int(NUM_SAMPLES_TRAIN * percentage_pois) # Number of poisoning points to generate\n",
    "    print(\"Creating {} poisoning samples \".format(n_poisoning_points))\n",
    "    # Should be chosen depending on the optimization problem\n",
    "    solver_params = {\n",
    "        'eta': 0.05,\n",
    "        'eta_min': 0.05,\n",
    "        'eta_max': None,\n",
    "        'max_iter': 1000,\n",
    "        'eps': 1e-6\n",
    "    }\n",
    "\n",
    "\n",
    "    pois_attack = CAttackPoisoningLogisticRegression(classifier=surrogate_clf,\n",
    "                                      training_data=training_set,\n",
    "                                      surrogate_classifier=surrogate_clf,\n",
    "                                      surrogate_data=validation_set,\n",
    "                                      val=validation_set,\n",
    "                                      distance='l1',\n",
    "                                      dmax=10,\n",
    "                                      lb=validation_set.X.min(), ub=validation_set.X.max(),\n",
    "                                      solver_params=solver_params,\n",
    "                                      random_seed=random_state,\n",
    "                                      init_type=\"random\")\n",
    "\n",
    "    pois_attack.n_points = n_poisoning_points\n",
    "    \n",
    "    #dimp_loss = CLossDisparateImpact(privileged_condition_validation)\n",
    "    #pois_attack._attacker_loss = dimp_loss\n",
    "\n",
    "    # Run the poisoning attack\n",
    "    print(\"Attack started...\")\n",
    "    pois_y_pred, pois_scores, pois_ds, f_opt = pois_attack.run(test_set.X, test_set.Y)\n",
    "    print(\"Attack complete!\")\n",
    "\n",
    "    \n",
    "    pois_tr = training_set.deepcopy().append(pois_ds)  # Join the training set with the poisoning points\n",
    "   \n",
    "    return pois_ds, pois_tr\n",
    "    \n",
    "    \n",
    "    "
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 4. Generate Disparate Impact scenario"
   ],
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "N=9 #Max euclidean distance between average of distributions\n",
    "n=1\n",
    "dimp_in_data = []\n",
    "euc_distances = []\n",
    "dimp_scenarios = []\n",
    "\n",
    "## Generating data\n",
    "X,y,sensitive_att_index = get_data()\n",
    "formatted_X=X ## Concatenating X with sensible att\n",
    "\n",
    "print(\"X_shape: \", X.shape)\n",
    "sensible_att_all = X[:,sensitive_att_index]\n",
    "sec_ml_dataset_all = CDataset(X, y)\n",
    "\n",
    "dimp_in_data.append(calculate_disparate_impact(sec_ml_dataset_all.Y.get_data(), sensible_att_all)) \n",
    "\n",
    "## Splitting data. \n",
    "X_train_val, X_test, y_train_val, y_test = train_test_split(formatted_X, y, test_size=0.2, random_state=random_state)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train_val, y_train_val, test_size=0.5, random_state=random_state)\n",
    "\n",
    "print(\"X_train: \", X_train.shape)\n",
    "training = CDataset(X_train, y_train)\n",
    "training_sensible_att = X_train[:,sensitive_att_index]\n",
    "\n",
    "validation = CDataset(X_val, y_val)\n",
    "validation_sensible_att = X_val[:,sensitive_att_index]\n",
    "val_lambda = np.zeros(validation.num_samples)\n",
    "\n",
    "## Creating lambda vector\n",
    "val_lambda[np.where((validation_sensible_att==0) & (y_val==0))[0]] == 1 ## Unprivileged denied\n",
    "val_lambda[np.where((validation_sensible_att==0) & (y_val==1))[0]] == 1 ## Unprivileged granted\n",
    "val_lambda[np.where((validation_sensible_att==1) & (y_val==0))[0]] == -1 ## Privileged denied\n",
    "val_lambda[np.where((validation_sensible_att==1) & (y_val==1))[0]] == -1 ## Privileged granted\n",
    "\n",
    "test = CDataset(X_test, y_test)\n",
    "test_sensible_att = X_test[:,sensitive_att_index]\n",
    "\n",
    "\n",
    "## GENERATING DATA FOR WHITE BOX ATTACK\n",
    "X2,y2,sensitive_att_index2 = get_data2()\n",
    "formatted_X2=X2 ## Concatenating X with sensible att\n",
    "\n",
    "sec_ml_dataset_all2 = CDataset(X2, y2)\n",
    "sensible_att_all2 = sec_ml_dataset_all2.X.get_data()[:,sensitive_att_index2]\n",
    "\n",
    "## Splitting data. \n",
    "X_train_val2, X_test2, y_train_val2, y_test2 = train_test_split(formatted_X2, y2, test_size=0.2, random_state=random_state)\n",
    "X_train2, X_val2, y_train2, y_val2 = train_test_split(X_train_val2, y_train_val2, test_size=0.5, random_state=random_state)\n",
    "\n",
    "training2 = CDataset(X_train2, y_train2)\n",
    "training_sensible_att2 = X_train2.ravel()\n",
    "\n",
    "validation2 = CDataset(X_val2, y_val2)\n",
    "validation_sensible_att2 = X_val2.ravel()\n",
    "val_lambda2 = np.zeros(validation2.num_samples)\n",
    "\n",
    "test2 = CDataset(X_test2, y_test2)\n",
    "test_sensible_att2 = X_test2.ravel()\n",
    "\n",
    "scenario = {\n",
    "    \"name\": \"Use case 4 - {}\".format(n),\n",
    "    \"description\": \"Disparate impact attack. \\n Euclidean distance between group averages: {}\\n\".format(n),\n",
    "    \"training\": training,\n",
    "    \"training_sensible_att\" : training_sensible_att,\n",
    "    \"validation\" : validation,\n",
    "    \"validation_sensible_att\" : validation_sensible_att,\n",
    "    \"lambda_validation\" : validation_sensible_att,\n",
    "    \"test\": test,\n",
    "    \"test_sensible_att\" : test_sensible_att,\n",
    "    \"all_data\" : sec_ml_dataset_all,\n",
    "    \"all_sensible_att\" : sensible_att_all,        \n",
    "    \"black_box_training\": training2,\n",
    "    \"black_box_training_sensible_att\" : training_sensible_att2,\n",
    "    \"black_box_validation\" : validation2,\n",
    "    \"black_box_validation_sensible_att\" : validation_sensible_att2,\n",
    "    \"black_box_lambda_validation\" : val_lambda2,\n",
    "    \"black_box_test\": test2,\n",
    "    \"black_box_test_sensible_att\" : test_sensible_att2,\n",
    "    \"black_box_all_data\" : sec_ml_dataset_all2,\n",
    "    \"black_box_all_sensible_att\" : sensible_att_all2,\n",
    "}\n",
    "    \n",
    "    \n",
    "dimp_scenarios.append(scenario)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "X_shape:  (1055, 10)\n",
      "X_train:  (422, 10)\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "for scenario in dimp_scenarios:\n",
    "    print(\"\\n\\n ==== {} ====\".format(scenario['name']))\n",
    "    print(\"    - {}\\n\".format(scenario['description']))\n",
    "    \n",
    "    ################################\n",
    "    ### ORIGINAL CLF PERFORMANCE ###\n",
    "    ################################\n",
    "    original_model, original_acc = train_LogReg(scenario[\"training\"], scenario[\"test\"])\n",
    "    \n",
    "    orig_y_pred = original_model.predict(scenario[\"test\"].X)\n",
    "    orig_FNR, orig_FPR = get_error_rates(scenario[\"test\"].Y.get_data(), orig_y_pred.get_data(), scenario[\"test_sensible_att\"], 1, 1)\n",
    "    orig_disparate_imp = calculate_disparate_impact(orig_y_pred.get_data(), scenario[\"test_sensible_att\"])\n",
    "    orig_odds_diff = get_average_odds_difference(scenario[\"test\"].Y.get_data(), orig_y_pred.get_data(), scenario[\"test_sensible_att\"])\n",
    "\n",
    "    scenario['original_classifier'] = original_model\n",
    "    scenario['original_acc'] = original_acc\n",
    "    scenario['orig_d_imp'] = orig_disparate_imp\n",
    "    scenario['orig_FNR'] = orig_FNR\n",
    "    scenario['orig_FPR'] = orig_FPR\n",
    "    scenario['orig_odds'] = orig_odds_diff\n",
    "    \n",
    "\n",
    "    ########################\n",
    "    ### WHITE BOX ATTACK ###\n",
    "    ########################\n",
    "    white_pois_clf = deepcopy(original_model)\n",
    "    \n",
    "    privileged_condition_valid = np.ones(scenario['validation'].num_samples)\n",
    "    privileged_condition_valid[scenario[\"validation_sensible_att\"] == 0] == -1\n",
    "    \n",
    "    \n",
    "    white_pois_points, white_pois_tr = execute_adversarial_attack(white_pois_clf, scenario[\"training\"], scenario[\"validation\"], scenario[\"test\"], scenario[\"test_sensible_att\"], scenario[\"validation_sensible_att\"])\n",
    "    ## Retraining with poisoned points\n",
    "    white_pois_clf = white_pois_clf.fit(white_pois_tr)\n",
    "    white_pois_y_pred = white_pois_clf.predict(scenario[\"test\"].X)\n",
    "    \n",
    "    metric = CMetricAccuracy()\n",
    "    white_pois_acc = metric.performance_score(scenario[\"test\"].Y, y_pred=white_pois_y_pred)\n",
    "    white_pois_disparate_imp = calculate_disparate_impact(white_pois_y_pred.get_data(), scenario[\"test_sensible_att\"])\n",
    "    white_pois_FNR, white_pois_FPR = get_error_rates(scenario[\"test\"].Y.get_data(), white_pois_y_pred.get_data(), scenario[\"test_sensible_att\"], 1, 1)\n",
    "    white_odds_diff = get_average_odds_difference(scenario[\"test\"].Y.get_data(), white_pois_y_pred.get_data(), scenario[\"test_sensible_att\"])\n",
    "\n",
    "    scenario['white_poisoned_classifier'] = white_pois_clf\n",
    "    scenario['white_poisoned_points'] = white_pois_points\n",
    "    scenario['white_pois_d_imp'] = white_pois_disparate_imp\n",
    "    scenario['white_pois_y_pred'] = white_pois_y_pred\n",
    "    scenario['white_pois_acc'] = white_pois_acc\n",
    "    scenario['white_pois_FNR'] = white_pois_FNR\n",
    "    scenario['white_pois_FPR'] = white_pois_FPR\n",
    "    scenario['white_odds'] = white_odds_diff\n",
    "    \n",
    "    \n",
    "    \n",
    "    ########################\n",
    "    ### BLACK BOX ATTACK ###\n",
    "    ########################\n",
    "    real_model, real_acc = train_SVM(scenario[\"training\"], scenario[\"test\"])\n",
    "    \n",
    "    surrogate_clf = deepcopy(original_model)\n",
    "    \n",
    "    black_pois_points, black_pois_tr = execute_adversarial_attack(surrogate_clf, scenario[\"training\"], scenario[\"validation\"], scenario[\"test\"], scenario[\"test_sensible_att\"], scenario[\"validation_sensible_att\"])\n",
    "    ## Retraining with poisoned points\n",
    "    \n",
    "    black_pois_clf = deepcopy(real_model)\n",
    "    black_pois_clf = black_pois_clf.fit(black_pois_tr)\n",
    "    black_pois_y_pred = black_pois_clf.predict(scenario[\"test\"].X)\n",
    "    \n",
    "    black_pois_acc = metric.performance_score(y_true=scenario[\"test\"].Y, y_pred=black_pois_y_pred)\n",
    "    black_pois_disparate_imp = calculate_disparate_impact(black_pois_y_pred.get_data(), scenario[\"test_sensible_att\"])\n",
    "    black_pois_FNR, black_pois_FPR = get_error_rates(scenario[\"test\"].Y.get_data(), black_pois_y_pred.get_data(), scenario[\"test_sensible_att\"], 1, 1)\n",
    "    black_odds_diff = get_average_odds_difference(scenario[\"test\"].Y.get_data(), black_pois_y_pred.get_data(), scenario[\"test_sensible_att\"])\n",
    "\n",
    "    scenario['black_poisoned_classifier'] = black_pois_clf\n",
    "    scenario['black_poisoned_points'] = black_pois_points\n",
    "    scenario['black_pois_d_imp'] = black_pois_disparate_imp\n",
    "    scenario['black_pois_y_pred'] = black_pois_y_pred\n",
    "    scenario['black_pois_acc'] = black_pois_acc\n",
    "    scenario['black_pois_FNR'] = black_pois_FNR\n",
    "    scenario['black_pois_FPR'] = black_pois_FPR\n",
    "    scenario['black_odds'] = black_odds_diff\n",
    "    \n",
    "    \n",
    "    \n",
    "    ################################\n",
    "    ### CLASSIC POISONING ATTACK ###\n",
    "    ################################\n",
    "    normal_pois_clf = deepcopy(original_model)\n",
    "    \n",
    "    privileged_condition_valid = np.ones(scenario['validation'].num_samples)\n",
    "    privileged_condition_valid[scenario[\"validation_sensible_att\"] == 0] == -1\n",
    "    \n",
    "    \n",
    "    normal_pois_points, normal_pois_tr = execute_normal_poisoning_attack(normal_pois_clf, scenario[\"training\"], scenario[\"validation\"], scenario[\"test\"], scenario[\"test_sensible_att\"], scenario[\"validation_sensible_att\"])\n",
    "    ## Retraining with poisoned points\n",
    "    normal_pois_clf = normal_pois_clf.fit(normal_pois_tr)\n",
    "    normal_pois_y_pred = normal_pois_clf.predict(scenario[\"test\"].X)\n",
    "    \n",
    "    metric = CMetricAccuracy()\n",
    "    normal_pois_acc = metric.performance_score(scenario[\"test\"].Y, y_pred=normal_pois_y_pred)\n",
    "    print(\"->> normal\")\n",
    "    normal_pois_disparate_imp = calculate_disparate_impact(normal_pois_y_pred.get_data(), scenario[\"test_sensible_att\"])\n",
    "    normal_odds_diff = get_average_odds_difference(scenario[\"test\"].Y.get_data(), normal_pois_y_pred.get_data(), scenario[\"test_sensible_att\"])\n",
    "    normal_pois_FNR, normal_pois_FPR = get_error_rates(scenario[\"test\"].Y.get_data(), normal_pois_y_pred.get_data(), scenario[\"test_sensible_att\"], 1, 1)\n",
    "    \n",
    "\n",
    "    scenario['normal_poisoned_classifier'] = normal_pois_clf\n",
    "    scenario['normal_poisoned_points'] = normal_pois_points\n",
    "    scenario['normal_pois_d_imp'] = normal_pois_disparate_imp\n",
    "    scenario['normal_odds'] = normal_odds_diff\n",
    "    scenario['normal_pois_y_pred'] = normal_pois_y_pred\n",
    "    scenario['normal_pois_acc'] = normal_pois_acc\n",
    "    scenario['normal_pois_FNR'] = normal_pois_FNR\n",
    "    scenario['normal_pois_FPR'] = normal_pois_FPR\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    "
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n",
      "\n",
      " ==== Use case 4 - 1 ====\n",
      "    - Disparate impact attack. \n",
      " Euclidean distance between group averages: 1\n",
      "\n",
      "\n",
      "Estimating the best training parameters...\n",
      "The best training parameters are:  {'C': 1}\n",
      "Training of classifier complete!\n",
      "Accuracy on test set: 67.30%\n",
      " ==> Adversarial attack. Percentage of samples: 0.2 \n",
      "Creating 84 poisoning samples \n",
      "Attack started...\n",
      "Attack complete!\n",
      "Estimating the best training parameters...\n",
      "The best training parameters are:  {'C': 10}\n",
      "Training of classifier complete!\n",
      "Accuracy on test set: 65.88%\n",
      " ==> Adversarial attack. Percentage of samples: 0.2 \n",
      "Creating 84 poisoning samples \n",
      "Attack started...\n",
      "Attack complete!\n",
      "Creating 84 poisoning samples \n",
      "Attack started...\n",
      "Attack complete!\n",
      "->> normal\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "source": [
    "from matplotlib.gridspec import GridSpec\n",
    "def plot_disparate_impact(scenarios, data_dimp=None , n_scenarios=1, title=None):\n",
    "    \n",
    "    x1 = [n for n in range(n_scenarios)]\n",
    "    \n",
    "    x1 = 1\n",
    "    x2 = 2.5\n",
    "    x3 = 4\n",
    "    \n",
    "    fig=plt.figure(figsize=[12,8])\n",
    "    if title is not None:\n",
    "        plt.suptitle(title, fontsize=14)\n",
    "\n",
    "    gs=GridSpec(2,4) # 2 rows, 3 columns\n",
    "\n",
    "    ax1=fig.add_subplot(gs[0,:2]) # Second row, span all columns\n",
    "    ax1.set_title(\"Accuracy\")\n",
    "    \n",
    "    ax1.bar(x1,[float(UC[\"original_acc\"]) for UC in scenarios], color=\"darkgreen\", label=\"Original classifier.\")\n",
    "    ax1.bar(x2,[float(UC[\"white_pois_acc\"]) for UC in scenarios], color=\"red\", label=\"Poisoned classifier. White box attack.\")\n",
    "    ax1.bar(x3,[float(UC[\"black_pois_acc\"]) for UC in scenarios], color=\"orange\", label=\"Poisoned classifier. Black box attack.\")\n",
    "    \n",
    "\n",
    "    ax2=fig.add_subplot(gs[0,2]) # First row, first column\n",
    "    ax2.set_title(\"DP\")\n",
    "    ax2.bar(x1,[UC[\"orig_d_imp\"] for UC in scenarios], color=\"darkgreen\", label=\"Original classifier.\")\n",
    "    #if data_dimp is not None:\n",
    "    #ax2.bar(0,data_dimp, color=\"darkgrey\", label=\"Original data\")\n",
    "    ax2.bar(x2,[UC[\"white_pois_d_imp\"] for UC in scenarios], color=\"red\", label=\"Poisoned classifier. White box attack.\")\n",
    "    ax2.bar(x3,[UC[\"black_pois_d_imp\"] for UC in scenarios], color=\"orange\", label=\"Poisoned classifier. Black box attack.\")\n",
    "\n",
    "    ax2b=fig.add_subplot(gs[0,3]) # First row, second column\n",
    "    ax2b.set_title(\"AOD\")\n",
    "\n",
    "    ax2b.bar(x1, [UC[\"orig_odds\"] for UC in scenarios], color=\"darkgreen\", label=\"Original classifier.\")\n",
    "    ax2b.bar(x2, [UC[\"white_odds\"] for UC in scenarios], color=\"red\", label=\"Poisoned classifier.White box attack\")\n",
    "    ax2b.bar(x3, [UC[\"black_odds\"] for UC in scenarios], color=\"orange\", label=\"Poisoned classifier. Black box attack\")\n",
    "\n",
    "    \n",
    "    ax3=fig.add_subplot(gs[1,0]) # First row, second column\n",
    "    ax3.set_title(\"FNR privileged\")\n",
    "    ax3.bar(x1,[UC[\"orig_FNR\"][\"FNR_privileged\"] for UC in scenarios], color=\"darkgreen\", label=\"Original classifier.\")\n",
    "    ax3.bar(x2,[UC[\"white_pois_FNR\"]['FNR_privileged'] for UC in scenarios], color=\"red\", label=\"Poisoned classifier. White box attack.\")\n",
    "    ax3.bar(x3,[UC[\"black_pois_FNR\"]['FNR_privileged'] for UC in scenarios], color=\"orange\", label=\"Poisoned classifier. Black box attack.\")\n",
    "\n",
    "    ax4=fig.add_subplot(gs[1,1]) # First row, third column\n",
    "    ax4.set_title(\"FNR unprivileged\")\n",
    "    ax4.bar(x1,[UC[\"orig_FNR\"][\"FNR_unprivileged\"] for UC in scenarios], color=\"darkgreen\", label=\"Original classifier.\")\n",
    "    ax4.bar(x2,[UC[\"white_pois_FNR\"]['FNR_unprivileged'] for UC in scenarios], color=\"red\", label=\"Poisoned classifier. White box attack.\")\n",
    "    ax4.bar(x3,[UC[\"black_pois_FNR\"]['FNR_unprivileged'] for UC in scenarios], color=\"orange\", label=\"Poisoned classifier. Black box attack.\")\n",
    "    #ax4.bar([], [], color=\"gray\", label=\"Disparate impact in the data\")\n",
    "    ax4.legend(bbox_to_anchor=(1.8, -0.1),fontsize=15)\n",
    "    \n",
    "    ax5=fig.add_subplot(gs[1,2]) # First row, second column\n",
    "    ax5.set_title(\"FPR privileged\")\n",
    "    ax5.bar(x1,[UC[\"orig_FPR\"][\"FPR_privileged\"] for UC in scenarios], color=\"darkgreen\", label=\"Original classifier.\")\n",
    "    ax5.bar(x2,[UC[\"white_pois_FPR\"]['FPR_privileged'] for UC in scenarios], color=\"red\", label=\"Poisoned classifier. White box attack.\")\n",
    "    ax5.bar(x3,[UC[\"black_pois_FPR\"]['FPR_privileged'] for UC in scenarios], color=\"orange\", label=\"Poisoned classifier. Black box attack.\")\n",
    "\n",
    "    ax6=fig.add_subplot(gs[1,3]) # First row, third column\n",
    "    ax6.set_title(\"FPR unprivileged\")\n",
    "    ax6.bar(x1,[UC[\"orig_FPR\"][\"FPR_unprivileged\"] for UC in scenarios], color=\"darkgreen\", label=\"Original classifier.\")\n",
    "    ax6.bar(x2,[UC[\"white_pois_FPR\"]['FPR_unprivileged'] for UC in scenarios], color=\"red\", label=\"Poisoned classifier. White box attack.\")\n",
    "    ax6.bar(x3,[UC[\"black_pois_FPR\"]['FPR_unprivileged'] for UC in scenarios], color=\"orange\", label=\"Poisoned classifier. Black box attack.\")\n",
    "\n",
    "    \n",
    "    ax1.set_xticks([])\n",
    "    ax2.set_xticks([])\n",
    "    ax3.set_xticks([])\n",
    "    ax4.set_xticks([])\n",
    "    ax5.set_xticks([])\n",
    "    ax6.set_xticks([])\n",
    "    \n",
    "    \n",
    "    plt.plot()\n",
    "    # plt.figure(figsize=[8,6])\n",
    "    plt.show()\n",
    "    plt.savefig('/home/gubin/boyangsun/Poisoning-Attacks-on-Algorithmic-Fairness-master/SecML/fairness/Output.png')\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "source": [
    "plot_disparate_impact(dimp_scenarios, dimp_in_data)"
   ],
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 864x576 with 7 Axes>"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "<Figure size 576x432 with 0 Axes>"
      ]
     },
     "metadata": {}
    }
   ],
   "metadata": {
    "scrolled": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "source": [
    "RANGE = np.arange(0.05, 0.31, 0.02)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "source": [
    "_results = []\n",
    "for i in range(5):\n",
    "    scenarios2 = []\n",
    "    for perc_pois in RANGE:\n",
    "        scenario = deepcopy(dimp_scenarios[0])\n",
    "\n",
    "        print(scenario[\"training\"])\n",
    "\n",
    "        print(\"\\n\\n ==== {}-{} ====\".format(scenario['name'], perc_pois))\n",
    "        print(\"    - {}\\n\".format(scenario['description']))\n",
    "\n",
    "        ################################\n",
    "        ### ORIGINAL CLF PERFORMANCE ###\n",
    "        ################################\n",
    "        original_model, original_acc = train_LogReg(scenario[\"training\"], scenario[\"test\"])\n",
    "\n",
    "        orig_y_pred = original_model.predict(scenario[\"test\"].X)\n",
    "        orig_FNR, orig_FPR = get_error_rates(scenario[\"test\"].Y.get_data(), orig_y_pred.get_data(), scenario[\"test_sensible_att\"], 1, 1)\n",
    "        orig_disparate_imp = calculate_disparate_impact(orig_y_pred.get_data(), scenario[\"test_sensible_att\"])\n",
    "        orig_odds_diff = get_average_odds_difference(scenario[\"test\"].Y.get_data(), orig_y_pred.get_data(), scenario[\"test_sensible_att\"])\n",
    "\n",
    "        scenario['original_classifier'] = original_model\n",
    "        scenario['original_acc'] = original_acc\n",
    "        scenario['orig_d_imp'] = orig_disparate_imp\n",
    "        scenario['orig_FNR'] = orig_FNR\n",
    "        scenario['orig_FPR'] = orig_FPR\n",
    "        scenario['orig_odds'] = orig_odds_diff\n",
    "\n",
    "\n",
    "        ########################\n",
    "        ### WHITE BOX ATTACK ###\n",
    "        ########################\n",
    "        white_pois_clf = deepcopy(original_model)\n",
    "\n",
    "        privileged_condition_valid = np.ones(scenario['validation'].num_samples)\n",
    "        privileged_condition_valid[scenario[\"validation_sensible_att\"] == 0] == -1\n",
    "\n",
    "\n",
    "        white_pois_points, white_pois_tr = execute_adversarial_attack(white_pois_clf, scenario[\"training\"], scenario[\"validation\"], scenario[\"test\"], scenario[\"test_sensible_att\"], scenario[\"validation_sensible_att\"], perc_pois)\n",
    "        ## Retraining with poisoned points\n",
    "        white_pois_clf = white_pois_clf.fit(white_pois_tr)\n",
    "        white_pois_y_pred = white_pois_clf.predict(scenario[\"test\"].X)\n",
    "\n",
    "        metric = CMetricAccuracy()\n",
    "        white_pois_acc = metric.performance_score(scenario[\"test\"].Y, y_pred=white_pois_y_pred)\n",
    "        white_pois_disparate_imp = calculate_disparate_impact(white_pois_y_pred.get_data(), scenario[\"test_sensible_att\"])\n",
    "        white_pois_FNR, white_pois_FPR = get_error_rates(scenario[\"test\"].Y.get_data(), white_pois_y_pred.get_data(), scenario[\"test_sensible_att\"], 1, 1)\n",
    "        white_odds_diff = get_average_odds_difference(scenario[\"test\"].Y.get_data(), white_pois_y_pred.get_data(), scenario[\"test_sensible_att\"])\n",
    "\n",
    "        scenario['white_poisoned_classifier'] = white_pois_clf\n",
    "        scenario['white_poisoned_points'] = white_pois_points\n",
    "        scenario['white_pois_d_imp'] = white_pois_disparate_imp\n",
    "        scenario['white_pois_y_pred'] = white_pois_y_pred\n",
    "        scenario['white_pois_acc'] = white_pois_acc\n",
    "        scenario['white_pois_FNR'] = white_pois_FNR\n",
    "        scenario['white_pois_FPR'] = white_pois_FPR\n",
    "        scenario['white_odds'] = white_odds_diff\n",
    "\n",
    "\n",
    "\n",
    "        ########################\n",
    "        ### BLACK BOX ATTACK ###\n",
    "        ########################\n",
    "        real_model, real_acc = train_SVM(scenario[\"training\"], scenario[\"test\"])\n",
    "\n",
    "        surrogate_clf = deepcopy(original_model)\n",
    "\n",
    "        black_pois_points, black_pois_tr = execute_adversarial_attack(surrogate_clf, scenario[\"training\"], scenario[\"validation\"], scenario[\"test\"], scenario[\"test_sensible_att\"], scenario[\"validation_sensible_att\"], perc_pois)\n",
    "        ## Retraining with poisoned points\n",
    "\n",
    "        black_pois_clf = deepcopy(real_model)\n",
    "        black_pois_clf = black_pois_clf.fit(black_pois_tr)\n",
    "        black_pois_y_pred = black_pois_clf.predict(scenario[\"test\"].X)\n",
    "\n",
    "        black_pois_acc = metric.performance_score(y_true=scenario[\"test\"].Y, y_pred=black_pois_y_pred)\n",
    "        black_pois_disparate_imp = calculate_disparate_impact(black_pois_y_pred.get_data(), scenario[\"test_sensible_att\"])\n",
    "        black_pois_FNR, black_pois_FPR = get_error_rates(scenario[\"test\"].Y.get_data(), black_pois_y_pred.get_data(), scenario[\"test_sensible_att\"], 1, 1)\n",
    "        black_odds_diff = get_average_odds_difference(scenario[\"test\"].Y.get_data(), black_pois_y_pred.get_data(), scenario[\"test_sensible_att\"])\n",
    "\n",
    "\n",
    "        scenario['black_poisoned_classifier'] = black_pois_clf\n",
    "        scenario['black_poisoned_points'] = black_pois_points\n",
    "        scenario['black_pois_d_imp'] = black_pois_disparate_imp\n",
    "        scenario['black_pois_y_pred'] = black_pois_y_pred\n",
    "        scenario['black_pois_acc'] = black_pois_acc\n",
    "        scenario['black_pois_FNR'] = black_pois_FNR\n",
    "        scenario['black_pois_FPR'] = black_pois_FPR\n",
    "        scenario['black_odds'] = black_odds_diff\n",
    "\n",
    "        ################################\n",
    "        ### CLASSIC POISONING ATTACK ###\n",
    "        ################################\n",
    "        normal_pois_clf = deepcopy(original_model)\n",
    "\n",
    "        privileged_condition_valid = np.ones(scenario['validation'].num_samples)\n",
    "        privileged_condition_valid[scenario[\"validation_sensible_att\"] == 0] == -1\n",
    "\n",
    "\n",
    "        normal_pois_points, normal_pois_tr = execute_normal_poisoning_attack(normal_pois_clf, scenario[\"training\"], scenario[\"validation\"], scenario[\"test\"], scenario[\"test_sensible_att\"], scenario[\"validation_sensible_att\"], perc_pois)\n",
    "        ## Retraining with poisoned points\n",
    "        normal_pois_clf = normal_pois_clf.fit(normal_pois_tr)\n",
    "        normal_pois_y_pred = normal_pois_clf.predict(scenario[\"test\"].X)\n",
    "\n",
    "        metric = CMetricAccuracy()\n",
    "        normal_pois_acc = metric.performance_score(scenario[\"test\"].Y, y_pred=normal_pois_y_pred)\n",
    "        print(\"->> normal\")\n",
    "        normal_pois_disparate_imp = calculate_disparate_impact(normal_pois_y_pred.get_data(), scenario[\"test_sensible_att\"])\n",
    "        normal_odds_diff = get_average_odds_difference(scenario[\"test\"].Y.get_data(), normal_pois_y_pred.get_data(), scenario[\"test_sensible_att\"])\n",
    "        normal_pois_FNR, normal_pois_FPR = get_error_rates(scenario[\"test\"].Y.get_data(), normal_pois_y_pred.get_data(), scenario[\"test_sensible_att\"], 1, 1)\n",
    "        normal_odds_diff = get_average_odds_difference(scenario[\"test\"].Y.get_data(), normal_pois_y_pred.get_data(), scenario[\"test_sensible_att\"])\n",
    "\n",
    "        scenario['normal_poisoned_classifier'] = normal_pois_clf\n",
    "        scenario['normal_poisoned_points'] = normal_pois_points\n",
    "        scenario['normal_pois_d_imp'] = normal_pois_disparate_imp\n",
    "        scenario['normal_odds'] = normal_odds_diff\n",
    "        scenario['normal_pois_y_pred'] = normal_pois_y_pred\n",
    "        scenario['normal_pois_acc'] = normal_pois_acc\n",
    "        scenario['normal_pois_FNR'] = normal_pois_FNR\n",
    "        scenario['normal_pois_FPR'] = normal_pois_FPR\n",
    "        scenario['normal_odds'] = normal_odds_diff\n",
    "\n",
    "\n",
    "        scenarios2.append(scenario)\n",
    "    _results.append(scenarios2)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "CDataset{'X': CArray(422, 10)(dense: [[1. 0. 0. ... 0. 1. 0.] [0. 0. 0. ... 0. 0. 1.] [0. 0. 1. ... 1. 1. 0.] ... [0. 0. 1. ... 1. 1. 0.] [0. 0. 1. ... 0. 0. 1.] [0. 1. 1. ... 0. 1. 0.]]), 'Y': CArray(422,)(dense: [1. 1. 0. ... 1. 1. 1.]), 'header': None}\n",
      "\n",
      "\n",
      " ==== Use case 4 - 1-0.05 ====\n",
      "    - Disparate impact attack. \n",
      " Euclidean distance between group averages: 1\n",
      "\n",
      "\n",
      "Estimating the best training parameters...\n",
      "The best training parameters are:  {'C': 1}\n",
      "Training of classifier complete!\n",
      "Accuracy on test set: 67.30%\n",
      " ==> Adversarial attack. Percentage of samples: 0.05 \n",
      "Creating 21 poisoning samples \n",
      "Attack started...\n",
      "Attack complete!\n",
      "Estimating the best training parameters...\n",
      "The best training parameters are:  {'C': 10}\n",
      "Training of classifier complete!\n",
      "Accuracy on test set: 65.88%\n",
      " ==> Adversarial attack. Percentage of samples: 0.05 \n",
      "Creating 21 poisoning samples \n",
      "Attack started...\n",
      "Attack complete!\n",
      "Creating 21 poisoning samples \n",
      "Attack started...\n",
      "Attack complete!\n",
      "->> normal\n",
      "CDataset{'X': CArray(422, 10)(dense: [[1. 0. 0. ... 0. 1. 0.] [0. 0. 0. ... 0. 0. 1.] [0. 0. 1. ... 1. 1. 0.] ... [0. 0. 1. ... 1. 1. 0.] [0. 0. 1. ... 0. 0. 1.] [0. 1. 1. ... 0. 1. 0.]]), 'Y': CArray(422,)(dense: [1. 1. 0. ... 1. 1. 1.]), 'header': None}\n",
      "\n",
      "\n",
      " ==== Use case 4 - 1-0.07 ====\n",
      "    - Disparate impact attack. \n",
      " Euclidean distance between group averages: 1\n",
      "\n",
      "\n",
      "Estimating the best training parameters...\n",
      "The best training parameters are:  {'C': 1}\n",
      "Training of classifier complete!\n",
      "Accuracy on test set: 67.30%\n",
      " ==> Adversarial attack. Percentage of samples: 0.07 \n",
      "Creating 29 poisoning samples \n",
      "Attack started...\n",
      "Attack complete!\n",
      "Estimating the best training parameters...\n",
      "The best training parameters are:  {'C': 10}\n",
      "Training of classifier complete!\n",
      "Accuracy on test set: 65.88%\n",
      " ==> Adversarial attack. Percentage of samples: 0.07 \n",
      "Creating 29 poisoning samples \n",
      "Attack started...\n",
      "Attack complete!\n",
      "Creating 29 poisoning samples \n",
      "Attack started...\n",
      "Attack complete!\n",
      "->> normal\n",
      "CDataset{'X': CArray(422, 10)(dense: [[1. 0. 0. ... 0. 1. 0.] [0. 0. 0. ... 0. 0. 1.] [0. 0. 1. ... 1. 1. 0.] ... [0. 0. 1. ... 1. 1. 0.] [0. 0. 1. ... 0. 0. 1.] [0. 1. 1. ... 0. 1. 0.]]), 'Y': CArray(422,)(dense: [1. 1. 0. ... 1. 1. 1.]), 'header': None}\n",
      "\n",
      "\n",
      " ==== Use case 4 - 1-0.09000000000000001 ====\n",
      "    - Disparate impact attack. \n",
      " Euclidean distance between group averages: 1\n",
      "\n",
      "\n",
      "Estimating the best training parameters...\n",
      "The best training parameters are:  {'C': 1}\n",
      "Training of classifier complete!\n",
      "Accuracy on test set: 67.30%\n",
      " ==> Adversarial attack. Percentage of samples: 0.09000000000000001 \n",
      "Creating 37 poisoning samples \n",
      "Attack started...\n",
      "Attack complete!\n",
      "Estimating the best training parameters...\n",
      "The best training parameters are:  {'C': 10}\n",
      "Training of classifier complete!\n",
      "Accuracy on test set: 65.88%\n",
      " ==> Adversarial attack. Percentage of samples: 0.09000000000000001 \n",
      "Creating 37 poisoning samples \n",
      "Attack started...\n",
      "Attack complete!\n",
      "Creating 37 poisoning samples \n",
      "Attack started...\n",
      "Attack complete!\n",
      "->> normal\n",
      "CDataset{'X': CArray(422, 10)(dense: [[1. 0. 0. ... 0. 1. 0.] [0. 0. 0. ... 0. 0. 1.] [0. 0. 1. ... 1. 1. 0.] ... [0. 0. 1. ... 1. 1. 0.] [0. 0. 1. ... 0. 0. 1.] [0. 1. 1. ... 0. 1. 0.]]), 'Y': CArray(422,)(dense: [1. 1. 0. ... 1. 1. 1.]), 'header': None}\n",
      "\n",
      "\n",
      " ==== Use case 4 - 1-0.11000000000000001 ====\n",
      "    - Disparate impact attack. \n",
      " Euclidean distance between group averages: 1\n",
      "\n",
      "\n",
      "Estimating the best training parameters...\n",
      "The best training parameters are:  {'C': 1}\n",
      "Training of classifier complete!\n",
      "Accuracy on test set: 67.30%\n",
      " ==> Adversarial attack. Percentage of samples: 0.11000000000000001 \n",
      "Creating 46 poisoning samples \n",
      "Attack started...\n",
      "Attack complete!\n",
      "Estimating the best training parameters...\n",
      "The best training parameters are:  {'C': 10}\n",
      "Training of classifier complete!\n",
      "Accuracy on test set: 65.88%\n",
      " ==> Adversarial attack. Percentage of samples: 0.11000000000000001 \n",
      "Creating 46 poisoning samples \n",
      "Attack started...\n",
      "Attack complete!\n",
      "Creating 46 poisoning samples \n",
      "Attack started...\n",
      "Attack complete!\n",
      "->> normal\n",
      "CDataset{'X': CArray(422, 10)(dense: [[1. 0. 0. ... 0. 1. 0.] [0. 0. 0. ... 0. 0. 1.] [0. 0. 1. ... 1. 1. 0.] ... [0. 0. 1. ... 1. 1. 0.] [0. 0. 1. ... 0. 0. 1.] [0. 1. 1. ... 0. 1. 0.]]), 'Y': CArray(422,)(dense: [1. 1. 0. ... 1. 1. 1.]), 'header': None}\n",
      "\n",
      "\n",
      " ==== Use case 4 - 1-0.13 ====\n",
      "    - Disparate impact attack. \n",
      " Euclidean distance between group averages: 1\n",
      "\n",
      "\n",
      "Estimating the best training parameters...\n",
      "The best training parameters are:  {'C': 1}\n",
      "Training of classifier complete!\n",
      "Accuracy on test set: 67.30%\n",
      " ==> Adversarial attack. Percentage of samples: 0.13 \n",
      "Creating 54 poisoning samples \n",
      "Attack started...\n",
      "Attack complete!\n",
      "Estimating the best training parameters...\n",
      "The best training parameters are:  {'C': 10}\n",
      "Training of classifier complete!\n",
      "Accuracy on test set: 65.88%\n",
      " ==> Adversarial attack. Percentage of samples: 0.13 \n",
      "Creating 54 poisoning samples \n",
      "Attack started...\n",
      "Attack complete!\n",
      "Creating 54 poisoning samples \n",
      "Attack started...\n",
      "Attack complete!\n",
      "->> normal\n",
      "CDataset{'X': CArray(422, 10)(dense: [[1. 0. 0. ... 0. 1. 0.] [0. 0. 0. ... 0. 0. 1.] [0. 0. 1. ... 1. 1. 0.] ... [0. 0. 1. ... 1. 1. 0.] [0. 0. 1. ... 0. 0. 1.] [0. 1. 1. ... 0. 1. 0.]]), 'Y': CArray(422,)(dense: [1. 1. 0. ... 1. 1. 1.]), 'header': None}\n",
      "\n",
      "\n",
      " ==== Use case 4 - 1-0.15000000000000002 ====\n",
      "    - Disparate impact attack. \n",
      " Euclidean distance between group averages: 1\n",
      "\n",
      "\n",
      "Estimating the best training parameters...\n",
      "The best training parameters are:  {'C': 1}\n",
      "Training of classifier complete!\n",
      "Accuracy on test set: 67.30%\n",
      " ==> Adversarial attack. Percentage of samples: 0.15000000000000002 \n",
      "Creating 63 poisoning samples \n",
      "Attack started...\n",
      "Attack complete!\n",
      "Estimating the best training parameters...\n",
      "The best training parameters are:  {'C': 10}\n",
      "Training of classifier complete!\n",
      "Accuracy on test set: 65.88%\n",
      " ==> Adversarial attack. Percentage of samples: 0.15000000000000002 \n",
      "Creating 63 poisoning samples \n",
      "Attack started...\n",
      "Attack complete!\n",
      "Creating 63 poisoning samples \n",
      "Attack started...\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_3103787/826929687.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     97\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 99\u001b[0;31m         \u001b[0mnormal_pois_points\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnormal_pois_tr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexecute_normal_poisoning_attack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnormal_pois_clf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscenario\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"training\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscenario\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"validation\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscenario\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"test\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscenario\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"test_sensible_att\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscenario\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"validation_sensible_att\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mperc_pois\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    100\u001b[0m         \u001b[0;31m## Retraining with poisoned points\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m         \u001b[0mnormal_pois_clf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnormal_pois_clf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnormal_pois_tr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_3103787/909193130.py\u001b[0m in \u001b[0;36mexecute_normal_poisoning_attack\u001b[0;34m(surrogate_clf, training_set, validation_set, test_set, sensible_att_in_test, privileged_condition_validation, percentage_pois)\u001b[0m\n\u001b[1;32m     79\u001b[0m     \u001b[0;31m# Run the poisoning attack\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Attack started...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 81\u001b[0;31m     \u001b[0mpois_y_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpois_scores\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpois_ds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf_opt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpois_attack\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_set\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_set\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     82\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Attack complete!\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/boyang/lib/python3.8/site-packages/secml-0.13.dev0-py3.8.egg/secml/adv/attacks/poisoning/c_attack_poisoning.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, x, y, ds_init, max_iter)\u001b[0m\n\u001b[1;32m    551\u001b[0m                 \u001b[0;31m# (and then re-optimize the first ones)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m                 \u001b[0midx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_points\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 553\u001b[0;31m                 \u001b[0mxc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    554\u001b[0m                 \u001b[0;31m# optimizing poisoning point 0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    555\u001b[0m                 self.logger.info(\n",
      "\u001b[0;32m~/anaconda3/envs/boyang/lib/python3.8/site-packages/secml-0.13.dev0-py3.8.egg/secml/adv/attacks/poisoning/c_attack_poisoning.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, xc, yc, idx)\u001b[0m\n\u001b[1;32m    472\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    473\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0my_target\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# indiscriminate attack\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 474\u001b[0;31m             \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_solver\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmaximize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_x0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    475\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# targeted attack\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    476\u001b[0m             \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_solver\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mminimize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_x0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/boyang/lib/python3.8/site-packages/secml-0.13.dev0-py3.8.egg/secml/optim/optimizers/c_optimizer.py\u001b[0m in \u001b[0;36mmaximize\u001b[0;34m(self, x_init, args, **kwargs)\u001b[0m\n\u001b[1;32m    189\u001b[0m         )\n\u001b[1;32m    190\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 191\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mminimize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_init\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    192\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    193\u001b[0m         \u001b[0;31m# fix solution variables\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/boyang/lib/python3.8/site-packages/secml-0.13.dev0-py3.8.egg/secml/optim/optimizers/c_optimizer_pgd_ls.py\u001b[0m in \u001b[0;36mminimize\u001b[0;34m(self, x_init, args, **kwargs)\u001b[0m\n\u001b[1;32m    306\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    307\u001b[0m             \u001b[0;31m# update point\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 308\u001b[0;31m             \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_xk\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    309\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    310\u001b[0m             \u001b[0;31m# Update history\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/boyang/lib/python3.8/site-packages/secml-0.13.dev0-py3.8.egg/secml/optim/optimizers/c_optimizer_pgd_ls.py\u001b[0m in \u001b[0;36m_xk\u001b[0;34m(self, x, fx, *args)\u001b[0m\n\u001b[1;32m    223\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mz\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfz\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    224\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 225\u001b[0;31m         \u001b[0mz\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfz\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_line_search\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mminimize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    226\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mz\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfz\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    227\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/boyang/lib/python3.8/site-packages/secml-0.13.dev0-py3.8.egg/secml/optim/optimizers/line_search/c_line_search_bisect.py\u001b[0m in \u001b[0;36mminimize\u001b[0;34m(self, x, d, fx, tol, **kwargs)\u001b[0m\n\u001b[1;32m    319\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meta_max\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    320\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Exponential search \"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 321\u001b[0;31m             \u001b[0meta_max\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compute_eta_max\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    322\u001b[0m             \u001b[0midx_max\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0meta_max\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meta\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mceil\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    323\u001b[0m             \u001b[0midx_min\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0midx_max\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/boyang/lib/python3.8/site-packages/secml-0.13.dev0-py3.8.egg/secml/optim/optimizers/line_search/c_line_search_bisect.py\u001b[0m in \u001b[0;36m_compute_eta_max\u001b[0;34m(self, x, d, **kwargs)\u001b[0m\n\u001b[1;32m    244\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    245\u001b[0m             \u001b[0;31m# update z and fz\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 246\u001b[0;31m             \u001b[0mz\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_update_z\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meta\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    247\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    248\u001b[0m             \u001b[0;31m# cache f_max\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/boyang/lib/python3.8/site-packages/secml-0.13.dev0-py3.8.egg/secml/optim/optimizers/line_search/c_line_search_bisect.py\u001b[0m in \u001b[0;36m_update_z\u001b[0;34m(self, x, eta, d)\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;34m\"\"\"Update z and its cached score fz.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m         \u001b[0mz\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0meta\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 95\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fz\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfun\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     96\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mz\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/boyang/lib/python3.8/site-packages/secml-0.13.dev0-py3.8.egg/secml/optim/function/c_function.py\u001b[0m in \u001b[0;36mfun\u001b[0;34m(self, x, *args, **kwargs)\u001b[0m\n\u001b[1;32m    104\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_ndim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 106\u001b[0;31m         \u001b[0mout_fun\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    107\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_fun_eval\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0matleast_2d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/boyang/lib/python3.8/site-packages/secml-0.13.dev0-py3.8.egg/secml/optim/optimizers/c_optimizer.py\u001b[0m in \u001b[0;36mfun_inv\u001b[0;34m(wrapped_fun, z, *f_args, **f_kwargs)\u001b[0m\n\u001b[1;32m    179\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    180\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mfun_inv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwrapped_fun\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mz\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mf_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mf_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 181\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0mwrapped_fun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mf_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mf_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    182\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    183\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mgrad_inv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwrapped_grad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mz\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mf_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mf_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/boyang/lib/python3.8/site-packages/secml-0.13.dev0-py3.8.egg/secml/optim/function/c_function.py\u001b[0m in \u001b[0;36mfun\u001b[0;34m(self, x, *args, **kwargs)\u001b[0m\n\u001b[1;32m    104\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_ndim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 106\u001b[0;31m         \u001b[0mout_fun\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    107\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_fun_eval\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0matleast_2d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/boyang/lib/python3.8/site-packages/secml-0.13.dev0-py3.8.egg/secml/adv/attacks/poisoning/c_attack_poisoning.py\u001b[0m in \u001b[0;36m_objective_function\u001b[0;34m(self, xc, acc)\u001b[0m\n\u001b[1;32m    365\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    366\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_xc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mxc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 367\u001b[0;31m         \u001b[0mclf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_update_poisoned_clf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    368\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    369\u001b[0m         \u001b[0;31m# targeted attacks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/boyang/lib/python3.8/site-packages/secml-0.13.dev0-py3.8.egg/secml/adv/attacks/poisoning/c_attack_poisoning.py\u001b[0m in \u001b[0;36m_update_poisoned_clf\u001b[0;34m(self, clf, tr, train_normalizer)\u001b[0m\n\u001b[1;32m    330\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_poisoned_clf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrain_normalizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_normalizer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    331\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 332\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_poisoned_clf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    333\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    334\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_poisoned_clf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/boyang/lib/python3.8/site-packages/secml-0.13.dev0-py3.8.egg/secml/ml/classifiers/c_classifier_linear.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, dataset, n_jobs)\u001b[0m\n\u001b[1;32m     96\u001b[0m                 \"training available on binary (2-classes) datasets only.\")\n\u001b[1;32m     97\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 98\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mCClassifierLinear\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     99\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/boyang/lib/python3.8/site-packages/secml-0.13.dev0-py3.8.egg/secml/ml/classifiers/c_classifier.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, dataset, n_jobs)\u001b[0m\n\u001b[1;32m    138\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m         \u001b[0;31m# Storing dataset classes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 140\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_classes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclasses\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    141\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_features\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_features\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    142\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/boyang/lib/python3.8/site-packages/secml-0.13.dev0-py3.8.egg/secml/data/c_dataset.py\u001b[0m in \u001b[0;36mclasses\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    181\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclasses\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    182\u001b[0m         \u001b[0;34m\"\"\"Classes (unique).\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 183\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mY\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    184\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    185\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/boyang/lib/python3.8/site-packages/secml-0.13.dev0-py3.8.egg/secml/array/c_array.py\u001b[0m in \u001b[0;36munique\u001b[0;34m(self, return_index, return_inverse, return_counts)\u001b[0m\n\u001b[1;32m   2801\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2802\u001b[0m         \"\"\"\n\u001b[0;32m-> 2803\u001b[0;31m         out = self._data.unique(\n\u001b[0m\u001b[1;32m   2804\u001b[0m             return_index, return_inverse, return_counts)\n\u001b[1;32m   2805\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# unique returned multiple elements\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/boyang/lib/python3.8/site-packages/secml-0.13.dev0-py3.8.egg/secml/array/c_dense.py\u001b[0m in \u001b[0;36munique\u001b[0;34m(self, return_index, return_inverse, return_counts)\u001b[0m\n\u001b[1;32m   1306\u001b[0m                return_inverse=False, return_counts=False):\n\u001b[1;32m   1307\u001b[0m         \u001b[0;34m\"\"\"Wrapper for unique.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1308\u001b[0;31m         out = np.unique(\n\u001b[0m\u001b[1;32m   1309\u001b[0m             self.tondarray(), return_index, return_inverse, return_counts)\n\u001b[1;32m   1310\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0many\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mreturn_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_inverse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_counts\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36munique\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/boyang/lib/python3.8/site-packages/numpy/lib/arraysetops.py\u001b[0m in \u001b[0;36munique\u001b[0;34m(ar, return_index, return_inverse, return_counts, axis)\u001b[0m\n\u001b[1;32m    260\u001b[0m     \u001b[0mar\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masanyarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mar\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    261\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0maxis\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 262\u001b[0;31m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_unique1d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mar\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_inverse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_counts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    263\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_unpack_tuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mret\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    264\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/boyang/lib/python3.8/site-packages/numpy/lib/arraysetops.py\u001b[0m in \u001b[0;36m_unique1d\u001b[0;34m(ar, return_index, return_inverse, return_counts)\u001b[0m\n\u001b[1;32m    308\u001b[0m         \u001b[0maux\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mar\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mperm\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    309\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 310\u001b[0;31m         \u001b[0mar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msort\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    311\u001b[0m         \u001b[0maux\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mar\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    312\u001b[0m     \u001b[0mmask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mempty\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maux\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbool_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from matplotlib.gridspec import GridSpec\n",
    "def plot_use_case_multiple_runs(scenarios, data_dimp=None , n_scenarios=5, title=None):\n",
    "    \n",
    "    _x_ = RANGE\n",
    "    \n",
    "    fig=plt.figure(figsize=[12,8])\n",
    "    if title is not None:\n",
    "        plt.suptitle(title, fontsize=14)\n",
    "\n",
    "    gs=GridSpec(2,4) # 2 rows, 3 columns\n",
    "\n",
    "    ax1=fig.add_subplot(gs[0,:2]) # Second row, span all columns\n",
    "    ax1.set_title(\"Accuracy\")\n",
    "    \n",
    "    ax1.plot(_x_,[float(UC[\"original_acc\"]) for UC in scenarios], c=\"darkgreen\", label=\"Original classifier.\")\n",
    "    ax1.plot(_x_,[float(UC[\"white_pois_acc\"]) for UC in scenarios], c=\"red\", label=\"Poisoned classifier. White box attack.\")\n",
    "    ax1.plot(_x_,[float(UC[\"black_pois_acc\"]) for UC in scenarios], c=\"orange\", label=\"Poisoned classifier. Black box attack.\")\n",
    "    ax1.plot(_x_,[float(UC[\"normal_pois_acc\"]) for UC in scenarios], '--', c=\"blue\", label=\"Classic poisoning attack\")\n",
    "    \n",
    "\n",
    "    ax2=fig.add_subplot(gs[0,2]) # First row, first column\n",
    "    ax2.set_title(\"Demographic parity\")\n",
    "    ax2.plot(_x_,[UC[\"orig_d_imp\"] for UC in scenarios], c=\"darkgreen\", label=\"Original classifier.\")\n",
    "    #if data_dimp is not None:\n",
    "    #    ax2.plot(_x_,data_dimp, c=\"darkgrey\", label=\"Original data\")\n",
    "    ax2.plot(_x_,[UC[\"white_pois_d_imp\"] for UC in scenarios], c=\"red\", label=\"Poisoned classifier. White box attack.\")\n",
    "    ax2.plot(_x_,[UC[\"black_pois_d_imp\"] for UC in scenarios], c=\"orange\", label=\"Poisoned classifier. Black box attack.\")\n",
    "    ax2.plot(_x_,[UC[\"normal_pois_d_imp\"] for UC in scenarios], '--', c=\"blue\", label=\"Classic poisoning attack\")\n",
    "    #ax2.legend(bbox_to_anchor=(1.1, -0.1),fontsize=15)\n",
    "    \n",
    "    ax2b=fig.add_subplot(gs[0,3]) # First row, first column\n",
    "    ax2b.set_title(\"Average odds difference\")\n",
    "    ax2b.plot(_x_,[UC[\"orig_odds\"] for UC in scenarios], c=\"darkgreen\", label=\"Original classifier.\")\n",
    "    ax2b.plot(_x_,[UC[\"white_odds\"] for UC in scenarios], c=\"red\", label=\"Poisoned classifier. White box attack.\")\n",
    "    ax2b.plot(_x_,[UC[\"black_odds\"] for UC in scenarios], c=\"orange\", label=\"Poisoned classifier. Black box attack.\")\n",
    "    ax2b.plot(_x_,[UC[\"normal_odds\"] for UC in scenarios], '--', c=\"blue\", label=\"Classic poisoning attack\")\n",
    "    \n",
    "    ax3=fig.add_subplot(gs[1,0]) # First row, second column\n",
    "    ax3.set_title(\"FNR privileged\")\n",
    "    ax3.plot(_x_,[UC[\"orig_FNR\"][\"FNR_privileged\"] for UC in scenarios], c=\"darkgreen\", label=\"Original classifier.\")\n",
    "    ax3.plot(_x_,[UC[\"white_pois_FNR\"]['FNR_privileged'] for UC in scenarios], c=\"red\", label=\"Poisoned classifier. White box attack.\")\n",
    "    ax3.plot(_x_,[UC[\"black_pois_FNR\"]['FNR_privileged'] for UC in scenarios], c=\"orange\", label=\"Poisoned classifier. Black box attack.\")\n",
    "    ax3.plot(_x_,[UC[\"normal_pois_FNR\"]['FNR_privileged'] for UC in scenarios], '--', c=\"blue\", label=\"Classic poisoning attack\")\n",
    "\n",
    "    ax4=fig.add_subplot(gs[1,1]) # First row, third column\n",
    "    ax4.set_title(\"FNR unprivileged\")\n",
    "    ax4.plot(_x_,[UC[\"orig_FNR\"][\"FNR_unprivileged\"] for UC in scenarios], c=\"darkgreen\", label=\"Original classifier.\")\n",
    "    ax4.plot(_x_,[UC[\"white_pois_FNR\"]['FNR_unprivileged'] for UC in scenarios], c=\"red\", label=\"Poisoned classifier. White box attack.\")\n",
    "    ax4.plot(_x_,[UC[\"black_pois_FNR\"]['FNR_unprivileged'] for UC in scenarios], c=\"orange\", label=\"Poisoned classifier. Black box attack.\")\n",
    "    ax4.plot(_x_,[UC[\"normal_pois_FNR\"]['FNR_unprivileged'] for UC in scenarios], '--', c=\"blue\", label=\"Classic poisoning attack\")\n",
    "    #ax4.plot([], [], c=\"gray\", label=\"Disparate impact in the data\")\n",
    "    \n",
    "    ax4.legend(bbox_to_anchor=(1.8, -0.1),fontsize=15)\n",
    "    \n",
    "    ax5=fig.add_subplot(gs[1,2]) # First row, second column\n",
    "    ax5.set_title(\"FPR privileged\")\n",
    "    ax5.plot(_x_,[UC[\"orig_FPR\"][\"FPR_privileged\"] for UC in scenarios], c=\"darkgreen\", label=\"Original classifier.\")\n",
    "    ax5.plot(_x_,[UC[\"white_pois_FPR\"]['FPR_privileged'] for UC in scenarios], c=\"red\", label=\"Poisoned classifier. White box attack.\")\n",
    "    ax5.plot(_x_,[UC[\"black_pois_FPR\"]['FPR_privileged'] for UC in scenarios], c=\"orange\", label=\"Poisoned classifier. Black box attack.\")\n",
    "    ax5.plot(_x_,[UC[\"normal_pois_FPR\"]['FPR_privileged'] for UC in scenarios], '--', c=\"blue\", label=\"Classic poisoning attack\")\n",
    "\n",
    "    ax6=fig.add_subplot(gs[1,3]) # First row, third column\n",
    "    ax6.set_title(\"FPR unprivileged\")\n",
    "    ax6.plot(_x_,[UC[\"orig_FPR\"][\"FPR_unprivileged\"] for UC in scenarios], c=\"darkgreen\", label=\"Original classifier.\")\n",
    "    ax6.plot(_x_,[UC[\"white_pois_FPR\"]['FPR_unprivileged'] for UC in scenarios], c=\"red\", label=\"Poisoned classifier. White box attack.\")\n",
    "    ax6.plot(_x_,[UC[\"black_pois_FPR\"]['FPR_unprivileged'] for UC in scenarios], c=\"orange\", label=\"Poisoned classifier. Black box attack.\")\n",
    "    ax6.plot(_x_,[UC[\"normal_pois_FPR\"]['FPR_unprivileged'] for UC in scenarios], '--', c=\"blue\", label=\"Classic poisoning attack\")\n",
    "    \n",
    "    plt.plot()\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "plot_use_case_multiple_runs(scenarios2, dimp_in_data)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "len(scenarios2)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "## Using different algorithms as black box"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "def train_models(X,y, X_test, y_test, sentitive_att_test):\n",
    "    m1 = DecisionTreeClassifier().fit(X, y)\n",
    "    m2 = RandomForestClassifier().fit(X, y)\n",
    "    m3 = LogisticRegression(random_state=0).fit(X, y)\n",
    "    m4 = SVC(kernel='linear').fit(X, y)\n",
    "    m5 = GaussianNB().fit(X, y)\n",
    "    #m6 = KNeighborsClassifier().fit(X, y)\n",
    "    m7 = SVC(gamma='auto', kernel='rbf').fit(X,y)\n",
    "    \n",
    "    ms = [m1,m2,m3,m4,m5,m7]\n",
    "\n",
    "    accs = []\n",
    "    dimp = []\n",
    "    avg_odds = []\n",
    "    \n",
    "    for m in ms:\n",
    "        _preds = m.predict(X_test)\n",
    "        accs.append(accuracy_score(y_test, _preds))\n",
    "        dimp.append(calculate_disparate_impact(_preds, sentitive_att_test))\n",
    "        avg_odds.append(get_average_odds_difference(y_test, _preds, sentitive_att_test))\n",
    "\n",
    "    return accs,dimp,avg_odds"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "_tmp = []\n",
    "for i in range(len(_results[0])):\n",
    "    \n",
    "    t = []\n",
    "    for j in range(len(_results)):\n",
    "    \n",
    "\n",
    "        sc = _results[j][i]\n",
    "        tr = sc['training']\n",
    "        ts = sc['test']\n",
    "        ps = sc['white_poisoned_points']\n",
    "        tr2 = tr.deepcopy().append(ps)\n",
    "        sensitive_att = sc['test_sensible_att']\n",
    "        for z in range(3):\n",
    "            t.append(train_models(tr2.X.get_data(), tr2.Y.get_data(), ts.X.get_data(), ts.Y.get_data(), sensitive_att))\n",
    "\n",
    "    accs = [c[0] for c in t]\n",
    "    dimps = [c[1] for c in t]\n",
    "    odds = [c[2] for c in t]\n",
    "\n",
    "    accs_means = np.array(accs).mean(0)\n",
    "    dimp_means = np.array(dimps).mean(0)\n",
    "    odds_means = np.array(odds).mean(0)\n",
    "    _tmp.append((accs_means, dimp_means, odds_means))\n",
    "\n",
    "accs = [c[0] for c in _tmp]\n",
    "dimps = [c[1] for c in _tmp]\n",
    "odds = [c[2] for c in _tmp]\n",
    "\n",
    "models = [\"DecisionTree\", \"RandomForest\", \"LogReg\", \"Linear SVM\", \"GaussianNB\", \"RBF SVM\"]\n",
    "model_cs = ['b', 'g', 'k', 'r', 'm', 'k']\n",
    "model_ms = ['^', (8,2,0), 'v', 'o', '+', '*']"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "fig=plt.figure(figsize=[16,4])\n",
    "ax=fig.add_subplot(131)\n",
    "\n",
    "_x_ = RANGE\n",
    "for i in range(len(accs[0])):\n",
    "    t = [acc[i] for acc in accs]\n",
    "    ax.plot(_x_,t,c=model_cs[i],marker=model_ms[i],ls=':',label=models[i])\n",
    "    \n",
    "#ax.set_xlabel(_x_)    \n",
    "ax.set_xlabel(\"% of poisoned samples\")\n",
    "ax.set_title(\"Accuracy\")\n",
    "\n",
    "\n",
    "ax2=fig.add_subplot(132)\n",
    "\n",
    "_x_ = RANGE\n",
    "for i in range(len(accs[0])):\n",
    "    t = [dimp[i] for dimp in dimps]\n",
    "    ax2.plot(_x_,t,c=model_cs[i],marker=model_ms[i],ls=':',label=models[i])\n",
    "    \n",
    "#ax.set_xlabel(_x_)    \n",
    "ax2.set_xlabel(\"% of poisoned samples\")\n",
    "ax2.set_title(\"Demographic parity\")\n",
    "\n",
    "\n",
    "ax3=fig.add_subplot(133)\n",
    "\n",
    "_x_ = RANGE\n",
    "for i in range(len(accs[0])):\n",
    "    t = [odd[i] for odd in odds]\n",
    "    ax3.plot(_x_,t,c=model_cs[i],marker=model_ms[i],ls=':',label=models[i])\n",
    "    \n",
    "#ax.set_xlabel(_x_)    \n",
    "ax3.set_xlabel(\"% of poisoned samples\")\n",
    "ax3.set_title(\"Average odds difference\")\n",
    "\n",
    "ax2.legend(bbox_to_anchor=(1.4, -.2), fontsize=15, ncol=3)\n",
    "fig.suptitle(\"Performance of transfer attacks\", x=0.5, y=1.1, fontsize=18)\n",
    "plt.show()\n",
    "fig.savefig(\"attack_compas_data_transf.eps\", format='eps')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def train_models2(ms, black_model, train_set, black_train_set, test_set, sensitive_att):\n",
    "    \n",
    "    accs = []\n",
    "    dimp = []\n",
    "    avg_odds = []\n",
    "    \n",
    "    y_test = test_set.Y.get_data()\n",
    "    \n",
    "    for m in ms:\n",
    "        #m = m.fit(train_set)\n",
    "        _preds = m.predict(test_set.X).get_data()\n",
    "        accs.append(accuracy_score(y_test, _preds))\n",
    "        dimp.append(calculate_disparate_impact(_preds, sensitive_att))\n",
    "        avg_odds.append(get_average_odds_difference(y_test, _preds, sensitive_att))\n",
    "\n",
    "\n",
    "    black_model = black_model.fit(black_train_set)   \n",
    "    _preds2 = black_model.predict(test_set.X).get_data()\n",
    "    \n",
    "    accs.append(accuracy_score(y_test, _preds2))\n",
    "    dimp.append(calculate_disparate_impact(_preds2, sensitive_att))\n",
    "    avg_odds.append(get_average_odds_difference(y_test, _preds2, sensitive_att))    \n",
    "\n",
    "    return accs,dimp,avg_odds\n",
    "    "
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "accs = []\n",
    "dimps = []\n",
    "odds_means = []\n",
    "_tmp = []\n",
    "for i in range(len(_results[0])):\n",
    "    \n",
    "    t = []\n",
    "    for j in range(len(_results)):\n",
    "    \n",
    "\n",
    "        sc = _results[j][i]\n",
    "        tr = sc['training']\n",
    "        ts = sc['test']\n",
    "        ps = sc['white_poisoned_points']\n",
    "        ps2 = sc['black_poisoned_points']\n",
    "        \n",
    "        m1 = sc['original_classifier']\n",
    "        m2 = sc['white_poisoned_classifier']\n",
    "        black_m = sc['black_poisoned_classifier']\n",
    "        m4 = sc['normal_poisoned_classifier']\n",
    "        ms = [m1,m2,m4]\n",
    "        \n",
    "        tr = tr.deepcopy().append(ps)\n",
    "        tr2 = tr.deepcopy().append(ps2)\n",
    "        \n",
    "        sensitive_att = sc['test_sensible_att']\n",
    "        \n",
    "        #for z in range(3):\n",
    "        t.append(train_models2(ms, black_m, tr, tr2, ts, sensitive_att))\n",
    "\n",
    "    accs = [c[0] for c in t]\n",
    "    dimps = [c[1] for c in t]\n",
    "    odds = [c[2] for c in t]\n",
    "\n",
    "    accs_means = np.array(accs).mean(0)\n",
    "    dimp_means = np.array(dimps).mean(0)\n",
    "    odds_means = np.array(odds).mean(0)\n",
    "    _tmp.append((accs_means, dimp_means, odds_means))\n",
    "\n",
    "accs = [c[0] for c in _tmp]\n",
    "dimps = [c[1] for c in _tmp]\n",
    "odds = [c[2] for c in _tmp]\n",
    "\n",
    "models = [\"Original model\", \"White-box attack\", \"Error-generic poisoning attack\", \"Black-box attack\"]\n",
    "model_cs = ['g', 'r', 'b', 'orange']\n",
    "model_ms = ['^', (8,2,0), 'v', 'o', '+', '*']"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "fig=plt.figure(figsize=[16,4])\n",
    "ax=fig.add_subplot(131)\n",
    "\n",
    "_x_ = RANGE\n",
    "for i in range(len(accs[0])):\n",
    "    t = [acc[i] for acc in accs]\n",
    "    ax.plot(_x_,t,c=model_cs[i],marker=model_ms[i],ls=':',label=models[i])\n",
    "    \n",
    "#ax.set_xlabel(_x_)    \n",
    "ax.set_xlabel(\"% of poisoned samples\")\n",
    "ax.set_title(\"Accuracy\")\n",
    "\n",
    "\n",
    "ax2=fig.add_subplot(132)\n",
    "\n",
    "_x_ = RANGE\n",
    "for i in range(len(accs[0])):\n",
    "    t = [dimp[i] for dimp in dimps]\n",
    "    ax2.plot(_x_,t,c=model_cs[i],marker=model_ms[i],ls=':',label=models[i])\n",
    "    \n",
    "#ax.set_xlabel(_x_)    \n",
    "ax2.set_xlabel(\"% of poisoned samples\")\n",
    "ax2.set_title(\"Demographic parity\")\n",
    "\n",
    "\n",
    "ax3=fig.add_subplot(133)\n",
    "\n",
    "_x_ = RANGE\n",
    "for i in range(len(accs[0])):\n",
    "    t = [odd[i] for odd in odds]\n",
    "    ax3.plot(_x_,t,c=model_cs[i],marker=model_ms[i],ls=':',label=models[i])\n",
    "    \n",
    "#ax.set_xlabel(_x_)    \n",
    "ax3.set_xlabel(\"% of poisoned samples\")\n",
    "ax3.set_title(\"Average odds difference\")\n",
    "\n",
    " \n",
    "ax2.legend(bbox_to_anchor=(2, -.2), fontsize=15, ncol=4)\n",
    "fig.suptitle(\"Performance of attacks on COMPAS data\", x=0.5, y=1.1)\n",
    "plt.show()\n",
    "\n",
    "fig.savefig(\"attack_compas_data3.eps\", format='eps')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def train_models2(ms, black_model, train_set, black_train_set, test_set, sensitive_att):\n",
    "    \n",
    "    accs = []\n",
    "    dimp = []\n",
    "    avg_odds = []\n",
    "    \n",
    "    fpr_priv = []\n",
    "    fpr_unpriv = []\n",
    "    fnr_priv = []\n",
    "    fnr_unpriv = []\n",
    "    \n",
    "    y_test = test_set.Y.get_data()\n",
    "    \n",
    "    for m in ms:\n",
    "        #m = m.fit(train_set)\n",
    "        _preds = m.predict(test_set.X).get_data()\n",
    "        accs.append(accuracy_score(y_test, _preds))\n",
    "        dimp.append(calculate_disparate_impact(_preds, sensitive_att))\n",
    "        avg_odds.append(get_average_odds_difference(y_test, _preds, sensitive_att))\n",
    "        \n",
    "        errors = get_error_rates(y_test, _preds, sensitive_att)\n",
    "        \n",
    "        fnr_priv.append(errors[0]['FNR_privileged'])\n",
    "        fnr_unpriv.append(errors[0]['FNR_unprivileged'])\n",
    "        \n",
    "        fpr_priv.append(errors[1]['FPR_privileged'])\n",
    "        fpr_unpriv.append(errors[1]['FPR_unprivileged'])\n",
    "\n",
    "    #black_model = black_model.fit(black_train_set)   \n",
    "    _preds2 = black_model.predict(test_set.X).get_data()\n",
    "    \n",
    "    accs.append(accuracy_score(y_test, _preds2))\n",
    "    dimp.append(calculate_disparate_impact(_preds2, sensitive_att))\n",
    "    avg_odds.append(get_average_odds_difference(y_test, _preds2, sensitive_att))  \n",
    "    errors = get_error_rates(y_test, _preds2, sensitive_att)\n",
    "        \n",
    "    fnr_priv.append(errors[0]['FNR_privileged'])\n",
    "    fnr_unpriv.append(errors[0]['FNR_unprivileged'])\n",
    "\n",
    "    fpr_priv.append(errors[1]['FPR_privileged'])\n",
    "    fpr_unpriv.append(errors[1]['FPR_unprivileged'])\n",
    "\n",
    "    return accs,dimp,avg_odds, fnr_priv, fnr_unpriv, fpr_priv, fpr_unpriv\n",
    "    \n",
    "accs = []\n",
    "dimps = []\n",
    "odds_means = []\n",
    "_tmp = []\n",
    "for i in range(len(_results[0])):\n",
    "    \n",
    "    t = []\n",
    "    for j in range(len(_results)):\n",
    "    \n",
    "\n",
    "        sc = _results[j][i]\n",
    "        tr = sc['training']\n",
    "        ts = sc['test']\n",
    "        ps = sc['white_poisoned_points']\n",
    "        ps2 = sc['black_poisoned_points']\n",
    "        \n",
    "        m1 = sc['original_classifier']\n",
    "        m2 = sc['white_poisoned_classifier']\n",
    "        black_m = sc['black_poisoned_classifier']\n",
    "        m4 = sc['normal_poisoned_classifier']\n",
    "        ms = [m1,m2,m4]\n",
    "        \n",
    "        tr = tr.deepcopy().append(ps)\n",
    "        tr2 = tr.deepcopy().append(ps2)\n",
    "        \n",
    "        sensitive_att = sc['test_sensible_att']\n",
    "        \n",
    "        for z in range(3):\n",
    "            t.append(train_models2(ms, black_m, tr, tr2, ts, sensitive_att))\n",
    "\n",
    "    accs = [c[0] for c in t]\n",
    "    dimps = [c[1] for c in t]\n",
    "    odds = [c[2] for c in t]\n",
    "    fnr_priv = [c[3] for c in t] \n",
    "    fnr_unpriv = [c[4] for c in t]\n",
    "    fpr_priv = [c[5] for c in t]\n",
    "    fpr_unpriv = [c[6] for c in t]\n",
    "\n",
    "    accs_means = np.array(accs).mean(0)\n",
    "    dimp_means = np.array(dimps).mean(0)\n",
    "    odds_means = np.array(odds).mean(0)\n",
    "    fnr_p_means = np.array(fnr_priv).mean(0)\n",
    "    fnr_u_means = np.array(fnr_unpriv).mean(0)\n",
    "    fpr_p_means = np.array(fpr_priv).mean(0)\n",
    "    fpr_u_means = np.array(fpr_unpriv).mean(0)\n",
    "    \n",
    "    \n",
    "    \n",
    "    _tmp.append((accs_means, dimp_means, odds_means,fnr_p_means,fnr_u_means,fpr_p_means,fpr_u_means))\n",
    "\n",
    "accs = [c[0] for c in _tmp]\n",
    "dimps = [c[1] for c in _tmp]\n",
    "odds = [c[2] for c in _tmp]\n",
    "fnr_priv = [c[3] for c in _tmp] \n",
    "fnr_unpriv = [c[4] for c in _tmp]\n",
    "fpr_priv = [c[5] for c in _tmp]\n",
    "fpr_unpriv = [c[6] for c in _tmp]\n",
    "\n",
    "models = [\"Original model\", \"White-box attack\", \"Error-generic poisoning attack\", \"Black-box attack\"]\n",
    "model_cs = ['g', 'r', 'b', 'orange']\n",
    "model_ms = ['^', (8,2,0), 'v', 'o', '+', '*']\n",
    "\n",
    "\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "fig=plt.figure(figsize=[16,8])\n",
    "\n",
    "gs=GridSpec(2,4) # 2 rows, 4 columns\n",
    "\n",
    "ax=fig.add_subplot(gs[0,:2]) # Second row, span all columns\n",
    "\n",
    "\n",
    "_x_ = list(range(len(_results[0])))\n",
    "for i in range(len(accs[0])):\n",
    "    t = [acc[i] for acc in accs]\n",
    "    c = model_cs[i]\n",
    "    mark = model_ms[i]\n",
    "    l = models[i]\n",
    "    ax.plot(_x_,t,c=c,marker=mark,ls=':',label=l)\n",
    "    \n",
    "#ax.set_xlabel(_x_)    \n",
    "#ax.set_xlabel(\"Euclidean distance in data\")\n",
    "ax.set_title(\"Accuracy\")\n",
    "\n",
    "\n",
    "ax2=fig.add_subplot(gs[0,2]) # Second row, span all columns\n",
    "\n",
    "_x_ = list(range(len(_results[0])))\n",
    "for i in range(len(accs[0])):\n",
    "    t = [dimp[i] for dimp in dimps]\n",
    "    ax2.plot(_x_,t,c=model_cs[i],marker=model_ms[i],ls=':',label=models[i])\n",
    "    \n",
    "#ax.set_xlabel(_x_)    \n",
    "#ax2.set_xlabel(\"Euclidean distance\")\n",
    "ax2.set_title(\"Demographic parity\")\n",
    "\n",
    "\n",
    "ax3=fig.add_subplot(gs[0,3])\n",
    "\n",
    "_x_ = list(range(len(_results[0])))\n",
    "\n",
    "for i in range(len(accs[0])):\n",
    "    t = [odd[i] for odd in odds]\n",
    "    ax3.plot(_x_,t,c=model_cs[i],marker=model_ms[i],ls=':',label=models[i])\n",
    "    \n",
    "#ax.set_xlabel(_x_)    \n",
    "#ax3.set_xlabel(\"Euclidean distance\")\n",
    "ax3.set_title(\"Average odds difference\")\n",
    "\n",
    "\n",
    "ax4=fig.add_subplot(gs[1,0])\n",
    "\n",
    "_x_ = list(range(len(_results[0])))\n",
    "\n",
    "for i in range(len(accs[0])):\n",
    "    t = [fnr_p[i] for fnr_p in fnr_priv]\n",
    "    ax4.plot(_x_,t,c=model_cs[i],marker=model_ms[i],ls=':',label=models[i])\n",
    "    \n",
    "#ax.set_xlabel(_x_)    \n",
    "#ax4.set_xlabel(\"Euclidean distance\")\n",
    "ax4.set_title(\"FNR privileged\")\n",
    "\n",
    "ax5=fig.add_subplot(gs[1,1])\n",
    "\n",
    "_x_ = list(range(len(_results[0])))\n",
    "\n",
    "for i in range(len(accs[0])):\n",
    "    t = [fnr_up[i] for fnr_up in fnr_unpriv]\n",
    "    ax5.plot(_x_,t,c=model_cs[i],marker=model_ms[i],ls=':',label=models[i])\n",
    "    \n",
    "#ax.set_xlabel(_x_)    \n",
    "#ax5.set_xlabel(\"Euclidean distance\")\n",
    "ax5.set_title(\"FNR unprivileged\")\n",
    "\n",
    "ax6=fig.add_subplot(gs[1,2])\n",
    "\n",
    "_x_ = list(range(len(_results[0])))\n",
    "\n",
    "for i in range(len(accs[0])):\n",
    "    t = [fpr_p[i] for fpr_p in fpr_priv]\n",
    "    ax6.plot(_x_,t,c=model_cs[i],marker=model_ms[i],ls=':',label=models[i])\n",
    "    \n",
    "#ax.set_xlabel(_x_)    \n",
    "#ax6.set_xlabel(\"Euclidean distance\")\n",
    "ax6.set_title(\"FPR privileged\")\n",
    "\n",
    "ax7=fig.add_subplot(gs[1,3])\n",
    "\n",
    "_x_ = list(range(len(_results[0])))\n",
    "\n",
    "for i in range(len(accs[0])):\n",
    "    t = [fpr_up[i] for fpr_up in fpr_unpriv]\n",
    "    ax7.plot(_x_,t,c=model_cs[i],marker=model_ms[i],ls=':',label=models[i])\n",
    "    \n",
    "#ax.set_xlabel(_x_)    \n",
    "#ax7.set_xlabel(\"Euclidean distance\")\n",
    "ax7.set_title(\"FPR unprivileged\")\n",
    "\n",
    " \n",
    "ax6.legend(bbox_to_anchor=(0.5, -.2), fontsize=15)\n",
    "fig.suptitle(\"Performance of attacks on synthetic data\", x=0.5, y=1)\n",
    "\n",
    "\n",
    "\n",
    "fig.align_labels() \n",
    "plt.show()\n",
    "fig.savefig(\"attack_compas_data2.eps\", format='eps')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "accs"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "_metrics = [accs,dimps,odds,fnr_priv,fnr_unpriv,fpr_priv,fpr_unpriv]\n",
    "_metric_names = [\"Accuracy\", \"Demographic parity\", \"Average odds difference\", \"FNR priv\", \"FNR unpriv\", \"FPR priv\", \"FPR unpriv\"]\n",
    "for m_idx, m in enumerate(_metrics):\n",
    "    m = np.array(m)\n",
    "    if m_idx != 3:\n",
    "        print(\" -- {} -- \".format(_metric_names[m_idx]))\n",
    "        print(\" Generic/Orig: {}\".format(np.mean(m[:,2]/m[:,0])))\n",
    "        print(\" White/Orig: {}\".format(np.mean(m[:,3]/m[:,0])))\n",
    "        print(\" Black/Orig: {}\".format(np.mean(m[:,1]/m[:,0])))\n",
    "    else:        \n",
    "        print(\" -- {} -- \".format(_metric_names[m_idx]))\n",
    "        print(\" Generic/Orig: {}\".format(np.mean(m[:,2][:-1] / m[:,0][:-1])))\n",
    "        print(\" White/Orig: {}\".format(np.mean(m[:,3][:-1] / m[:,0][:-1])))\n",
    "        print(\" Black/Orig: {}\".format(np.mean(m[:,1][:-1] / m[:,0][:-1])))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.12 64-bit ('boyang': conda)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  },
  "interpreter": {
   "hash": "34c4e49c4f9e3a1240922b6c8f4b5fe32091c38701607690cb0893a17e19c27d"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}